{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_, out):\n",
    "    return nn.Conv2d(in_, out, 3, padding=1)\n",
    "\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super().__init__()\n",
    "        self.conv = conv3x3(in_, out)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NoOperation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            ConvRelu(in_channels, middle_channels),\n",
    "            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class DecoderBlockV2(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True,\n",
    "                output_padding=0):\n",
    "        super(DecoderBlockV2, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        if is_deconv:\n",
    "            \"\"\"\n",
    "                Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
    "                link https://distill.pub/2016/deconv-checkerboard/\n",
    "            \"\"\"\n",
    "\n",
    "            self.block = nn.Sequential(\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
    "                                   padding=1, output_padding=output_padding),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                ConvRelu(middle_channels, out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Interpolate(nn.Module):\n",
    "    def __init__(self, mode='nearest', scale_factor=2,\n",
    "                 align_corners=False, output_padding=0):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.interp = nn.functional.interpolate\n",
    "        self.mode = mode\n",
    "        self.scale_factor = scale_factor\n",
    "        self.align_corners = align_corners\n",
    "        self.pad = output_padding\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.mode in ['linear','bilinear','trilinear']:\n",
    "            x = self.interp(x, mode=self.mode,\n",
    "                            scale_factor=self.scale_factor,\n",
    "                            align_corners=self.align_corners)\n",
    "        else:\n",
    "            x = self.interp(x, mode=self.mode,\n",
    "                            scale_factor=self.scale_factor)\n",
    "            \n",
    "        if self.pad > 0:\n",
    "            x = nn.ZeroPad2d((0, self.pad, 0, self.pad))(x)\n",
    "        return x\n",
    "\n",
    "class DecoderBlockV3(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels,\n",
    "                 is_deconv=True, output_padding=0):\n",
    "        super(DecoderBlockV3, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        if is_deconv:\n",
    "            \"\"\"\n",
    "                Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
    "                link https://distill.pub/2016/deconv-checkerboard/\n",
    "            \"\"\"\n",
    "\n",
    "            self.block = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, middle_channels, kernel_size=4, stride=2,\n",
    "                                   padding=1, output_padding=output_padding),\n",
    "                ConvRelu(middle_channels, out_channels),\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                Interpolate(mode='nearest', scale_factor=2,\n",
    "                           output_padding=output_padding),\n",
    "                # nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                ConvRelu(middle_channels, out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, num_filters=32, \n",
    "                 pretrained=True, is_deconv=False):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.in0 = nn.InstanceNorm2d(3)\n",
    "        \n",
    "#         self.conv4to3 = nn.Conv2d(4, 3, 1)\n",
    "            \n",
    "#         self.encoder = pretrainedmodels.__dict__['se_resnext50_32x4d'](num_classes=1000,\n",
    "#                                               pretrained='imagenet') \n",
    "        \n",
    "        # code removes final layer\n",
    "#         layers = resnet34()\n",
    "        \n",
    "        layers = list(ptcv_get_model(\"airnext50_32x4d_r2\", pretrained=True).children())[:1]\n",
    "                \n",
    "#         # replace first convolutional layer by 4->64 while keeping corresponding weights\n",
    "#         # and initializing new weights with zeros\n",
    "#         # https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-448-public-lb/notebook\n",
    "#         w = layers[0].weight\n",
    "#         layers[0] = nn.Conv2d(4,64,kernel_size=(7,7),stride=(2,2),padding=(3, 3),\n",
    "#                               bias=False)\n",
    "#         layers[0].weight = torch.nn.Parameter(torch.cat((w,torch.zeros(64,1,7,7)),\n",
    "#                                                         dim=1))\n",
    "        \n",
    "        layers += [AdaptiveConcatPool2d()]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(4096)\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "#         self.conv1 = nn.Conv2d(4096, 256, kernel_size=(3,3), \n",
    "#                               stride=(1,1), padding=1)\n",
    "        self.conv1 = nn.Conv2d(4096, 256, kernel_size=(1,1), \n",
    "                              stride=(1,1), padding=0)\n",
    "\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "#         self.conv2 = nn.Conv2d(256, num_classes, kernel_size=(3,3), \n",
    "#                               stride=(1,1), padding=1)\n",
    "        self.conv2 = nn.Conv2d(256, num_classes, kernel_size=(1,1), \n",
    "                              stride=(1,1), padding=0)\n",
    "\n",
    "#         self.act3 = nn.ReLU()\n",
    "#         self.bn3 = nn.BatchNorm2d(256)\n",
    "#         self.do3 = nn.Dropout(p=0.3)\n",
    "#         self.conv3 = nn.Conv2d(256, num_classes, kernel_size=(3,3), \n",
    "#                               stride=(1,1), padding=1)\n",
    "\n",
    "#         self.encoder = nn.Sequential(*list(self.encoder.children())[:-1])\n",
    "\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.convp = nn.Conv2d(1056, 512, 3)\n",
    "\n",
    "#         self.csize = 1024 * 1 * 1\n",
    "#         self.bn1 = nn.BatchNorm1d(1024)\n",
    "#         self.do1 = nn.Dropout(p=0.5)\n",
    "#         self.lin1 = nn.Linear(1024, 512)\n",
    "#         self.act1 = nn.ReLU()\n",
    "#         self.bn2 = nn.BatchNorm1d(512)\n",
    "#         self.do2 = nn.Dropout(0.5)\n",
    "#         self.lin2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # set to True for debugging\n",
    "        print_sizes = False\n",
    "        if print_sizes: \n",
    "            print('')\n",
    "            print('x',x.shape)\n",
    "            \n",
    "        x = self.in0(x)\n",
    "        \n",
    "        # print layer dictionary\n",
    "        # print(self.encoder.features)\n",
    "        \n",
    "#         x = self.conv4to3(x)\n",
    "        \n",
    "        m = self.encoder._modules\n",
    "        layer_names = list(m.keys())\n",
    "        mx = {}\n",
    "        for i,f in enumerate(m):\n",
    "            x = m[f](x)\n",
    "            mx[layer_names[i]] = x\n",
    "            if print_sizes:\n",
    "                if isinstance(x,tuple):\n",
    "                    print(i,layer_names[i],x[0].size(),x[1].size())\n",
    "                else:\n",
    "                    print(i,layer_names[i],x.size())\n",
    "#             if layer_names[i]=='avg_pool': break\n",
    "                \n",
    "#         x = self.encoder(x)\n",
    "        if print_sizes: print('encoder',x.shape)\n",
    "\n",
    "        x = self.act1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.do1(x) \n",
    "        x = self.conv1(x)\n",
    "        if print_sizes: print('conv1',x.shape)\n",
    "\n",
    "        x = self.act2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.do2(x) \n",
    "        x = self.conv2(x)\n",
    "        if print_sizes: print('conv2',x.shape)\n",
    "\n",
    "#         x = self.act3(x)\n",
    "#         x = self.bn3(x)\n",
    "#         x = self.do3(x) \n",
    "#         x = self.conv3(x)\n",
    "#         if print_sizes: print('conv3',x.shape)\n",
    "\n",
    "#         x = self.map_logits(x)\n",
    "#         if print_sizes: print('map_logits',x.shape)\n",
    "\n",
    "#         x = x.view(-1, self.csize)\n",
    "#         if print_sizes: print('view',x.size())\n",
    "\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.do1(x)\n",
    "#         if print_sizes: print('do1',x.size())\n",
    "            \n",
    "#         x = self.lin1(x)\n",
    "#         if print_sizes: print('lin1',x.size())\n",
    "#         x = self.act1(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.do2(x) \n",
    "#         x = self.lin2(x)\n",
    "#         if print_sizes: print('lin2',x.shape)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
