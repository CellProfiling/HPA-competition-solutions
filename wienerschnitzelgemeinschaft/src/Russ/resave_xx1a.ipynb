{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "midx = '1a'\n",
    "# midx = '1a1'\n",
    "# midx = '1a2'\n",
    "# midx = '1a3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import timeit\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import random\n",
    "import PIL\n",
    "import pathlib\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau, StepLR\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torchvision\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from skimage.exposure import histogram, equalize_hist, equalize_adapthist\n",
    "from skimage.morphology import dilation, remove_small_objects, remove_small_holes, label\n",
    "\n",
    "import pretrainedmodels\n",
    "from xception import xception\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from scipy.special import logit\n",
    "from sklearn.metrics import jaccard_similarity_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import multiprocessing\n",
    "import threading\n",
    "\n",
    "from dataloaders import utils\n",
    "from dataloaders import custom_transforms as tr\n",
    "\n",
    "# from losses import CombinedLoss, BCELoss2d\n",
    "import lovasz_losses as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "7114b9f3da03d4688ecfdecd7c7008a0be0c8004",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 512 512\n"
     ]
    }
   ],
   "source": [
    "directory = './'\n",
    "\n",
    "ori_size = 512\n",
    "up_size = 512\n",
    "image_size = 512\n",
    "\n",
    "interp = cv2.INTER_AREA\n",
    "# methods=[(\"area\", cv2.INTER_AREA), \n",
    "#          (\"nearest\", cv2.INTER_NEAREST), \n",
    "#          (\"linear\", cv2.INTER_LINEAR), \n",
    "#          (\"cubic\", cv2.INTER_CUBIC), \n",
    "#          (\"lanczos4\", cv2.INTER_LANCZOS4)]\n",
    "\n",
    "y_pad = image_size - up_size\n",
    "y_min_pad = int(y_pad / 2)\n",
    "y_max_pad = y_pad - y_min_pad\n",
    "\n",
    "x_pad = image_size - up_size\n",
    "x_min_pad = int(x_pad / 2)\n",
    "x_max_pad = x_pad - x_min_pad\n",
    "\n",
    "print(ori_size, up_size, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TRAIN = './train/'\n",
    "PATH_TO_TEST = './test/'\n",
    "PATH_TO_EXTERNAL2 = './external_data2/'\n",
    "PATH_TO_EXTERNAL3 = './external_data3/'\n",
    "PATH_TO_TARGET = './train.csv'\n",
    "PATH_TO_TARGETXX = './HPAv18Y.csv'\n",
    "PATH_TO_SUB = './sample_submission.csv'\n",
    "\n",
    "LABEL_MAP = {\n",
    "0: \"Nucleoplasm\" ,\n",
    "1: \"Nuclear membrane\"   ,\n",
    "2: \"Nucleoli\"   ,\n",
    "3: \"Nucleoli fibrillar center\",   \n",
    "4: \"Nuclear speckles\"   ,\n",
    "5: \"Nuclear bodies\"   ,\n",
    "6: \"Endoplasmic reticulum\"   ,\n",
    "7: \"Golgi apparatus\"  ,\n",
    "8: \"Peroxisomes\"   ,\n",
    "9:  \"Endosomes\"   ,\n",
    "10: \"Lysosomes\"   ,\n",
    "11: \"Intermediate filaments\"  , \n",
    "12: \"Actin filaments\"   ,\n",
    "13: \"Focal adhesion sites\"  ,\n",
    "14: \"Microtubules\"   ,\n",
    "15: \"Microtubule ends\"   ,\n",
    "16: \"Cytokinetic bridge\"   ,\n",
    "17: \"Mitotic spindle\"  ,\n",
    "18: \"Microtubule organizing center\",  \n",
    "19: \"Centrosome\",\n",
    "20: \"Lipid droplets\"   ,\n",
    "21: \"Plasma membrane\"  ,\n",
    "22: \"Cell junctions\"   ,\n",
    "23: \"Mitochondria\"   ,\n",
    "24: \"Aggresome\"   ,\n",
    "25: \"Cytosol\" ,\n",
    "26: \"Cytoplasmic bodies\",\n",
    "27: \"Rods & rings\"}\n",
    "\n",
    "LOC_MAP = {}\n",
    "for k in LABEL_MAP.keys(): LOC_MAP[LABEL_MAP[k]] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "95e82b2a7155377310f1d743dd8b077f99cba657",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Target  GotYellow\n",
      "Id                                             \n",
      "ENSG00000000003_4109_24_H11_1     25          1\n",
      "ENSG00000000003_4109_24_H11_2     25          1\n",
      "ENSG00000000003_4109_23_H11_1     25          1\n",
      "ENSG00000000003_4109_23_H11_2     25          1\n",
      "ENSG00000000003_4109_25_H11_1     25          1\n",
      "(77878, 2)\n"
     ]
    }
   ],
   "source": [
    "# from Tomomi\n",
    "dxx = pd.read_csv(PATH_TO_TARGETXX, index_col = None)\n",
    "dxx.set_index('Id',inplace=True)\n",
    "print(dxx.head())\n",
    "print(dxx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77878, 2)\n"
     ]
    }
   ],
   "source": [
    "# dataloader bombs out on iteration 63914, so limit size here\n",
    "# dxx = dxx.iloc[:50000]\n",
    "# dxx = dxx.iloc[50000:]\n",
    "# dxx = dxx.iloc[37154:]\n",
    "print(dxx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_histogram_equalization(image, number_bins=256):\n",
    "    # from http://www.janeriksolem.net/2009/06/histogram-equalization-with-python-and.html\n",
    "\n",
    "    # get image histogram\n",
    "    image_histogram, bins = np.histogram(image.flatten(), number_bins, density=True)\n",
    "    cdf = image_histogram.cumsum() # cumulative distribution function\n",
    "    cdf = 255 * cdf / cdf[-1] # normalize\n",
    "\n",
    "    # use linear interpolation of cdf to find new pixel values\n",
    "    image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n",
    "\n",
    "    # return image_equalized.reshape(image.shape), cdf\n",
    "    return image_equalized.reshape(image.shape)\n",
    "\n",
    "def equalize(arr):\n",
    "    arr = arr.astype('float')\n",
    "    # usually do not touch the alpha channel\n",
    "    # but here we do since it is yellow\n",
    "    for i in range(arr.shape[-1]):\n",
    "        # arr[...,i] = 255 * equalize_hist(arr[...,i])\n",
    "        arr[...,i] = image_histogram_equalization(arr[...,i])                                  \n",
    "    return arr\n",
    "\n",
    "def normalize(arr, q=0.01):\n",
    "    arr = arr.astype('float')\n",
    "    # usually do not touch the alpha channel\n",
    "    # but here we do since it is yellow\n",
    "    # print('arr before',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    for i in range(arr.shape[-1]):\n",
    "        # arr[...,i] = 255 * equalize_hist(arr[...,i])\n",
    "        ai = arr[...,i]\n",
    "        # print('ai ' + str(i) + ' before',i,ai.shape,ai.min(),ai.mean(),ai.max())\n",
    "        qlow = np.percentile(ai,100*q)\n",
    "        qhigh = np.percentile(ai,100*(1.0-q))\n",
    "        if qlow == qhigh:\n",
    "            arr[...,i] = 0.\n",
    "        else:\n",
    "            arr[...,i] = 255.*(np.clip(ai,qlow,qhigh) - qlow)/(qhigh - qlow)                              \n",
    "        # print('ai ' + str(i) + ' after',i,ai.shape,ai.min(),ai.mean(),ai.max())\n",
    "    # print('arr after',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    return arr\n",
    "\n",
    "def standardize(arr):\n",
    "    arr = arr.astype('float')\n",
    "    # usually do not touch the alpha channel\n",
    "    # but here we do since it is yellow\n",
    "    # print('arr before',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    for i in range(arr.shape[-1]):\n",
    "        # arr[...,i] = 255 * equalize_hist(arr[...,i])\n",
    "        ai = (arr[...,i] - arr.mean())/(arr.std() + 1e-6)\n",
    "        # print('ai ' + str(i) + ' after',i,ai.shape,ai.min(),ai.mean(),ai.max())\n",
    "    # print('arr after',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "class MultiBandMultiLabelDataset(Dataset):\n",
    "    \n",
    "#     BANDS_NAMES = ['_red.png','_green.png','_blue.png','_yellow.png']\n",
    "    BANDS_NAMES = ['_red','_green','_blue']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_df)\n",
    "    \n",
    "    def __init__(self, images_df, \n",
    "                 base_path, \n",
    "                 image_transform=None, \n",
    "                 augmentator=None,\n",
    "                 train_mode=True,\n",
    "                 external=0\n",
    "                ):\n",
    "        if not isinstance(base_path, pathlib.Path):\n",
    "            base_path = pathlib.Path(base_path)\n",
    "            \n",
    "        self.images_df = images_df.reset_index()\n",
    "        self.image_transform = image_transform\n",
    "        self.augmentator = augmentator\n",
    "        self.images_df.Id = self.images_df.Id.apply(lambda x: base_path / x)\n",
    "        self.mlb = MultiLabelBinarizer(classes=list(LABEL_MAP.keys()))\n",
    "        self.train_mode = train_mode\n",
    "        self.external = external\n",
    "        if self.external == 2: self.suffix = '.jpg'\n",
    "        else: self.suffix = '.png'\n",
    "        self.cache = {}\n",
    "                                 \n",
    "    def __getitem__(self, index):\n",
    "        # print('index class',index.__class__)\n",
    "        if isinstance(index, torch.Tensor): index = index.item()\n",
    "        if index in self.cache: \n",
    "            X, y = self.cache[index]\n",
    "        else:\n",
    "            y = None\n",
    "            X = self._load_multiband_image(index)\n",
    "            if self.train_mode:\n",
    "                y = self._load_multilabel_target(index)\n",
    "            self.cache[index] = (X,y)\n",
    "        \n",
    "        # augmentator can be for instance imgaug augmentation object\n",
    "        if self.augmentator is not None:\n",
    "#             print('getitem before aug',X.shape,np.min(X),np.mean(X),np.max(X))\n",
    "#             X = self.augmentator(np.array(X))\n",
    "            X = self.augmentator(image=X)['image']\n",
    "#             print('getitem after aug',X.shape,np.min(X),np.mean(X),np.max(X))\n",
    "           \n",
    "        if self.image_transform is not None:\n",
    "            X = self.image_transform(X)\n",
    "        \n",
    "        return X, y \n",
    "        \n",
    "    def _load_multiband_image(self, index):\n",
    "        row = self.images_df.iloc[index]\n",
    "        \n",
    "        if self.external == 1:\n",
    "            p = str(row.Id.absolute()) + self.suffix\n",
    "            band3image = PIL.Image.open(p)\n",
    "    \n",
    "        else:\n",
    "            image_bands = []\n",
    "            for i,band_name in enumerate(self.BANDS_NAMES):\n",
    "                p = str(row.Id.absolute()) + band_name + self.suffix\n",
    "                pil_channel = PIL.Image.open(p)\n",
    "                if self.external == 2: \n",
    "                    pa = np.array(pil_channel)[...,i]  \n",
    "#                     pa = np.array(pil_channel)\n",
    "#                     print(i,band_name,pil_channel.mode,pa.shape,pa.min(),pa.mean(),pa.max())\n",
    "                    if pa.max() > 0:\n",
    "                        pil_channel = PIL.Image.fromarray(pa.astype('uint8'),'L')\n",
    "                    pil_channel = pil_channel.convert(\"L\")\n",
    "                image_bands.append(pil_channel)\n",
    "\n",
    "            # pretend its a RBGA image to support 4 channels\n",
    "#             band4image = PIL.Image.merge('RGBA', bands=image_bands)\n",
    "            band3image = PIL.Image.merge('RGB', bands=image_bands)\n",
    "    \n",
    "        band3image = band3image.resize((image_size,image_size), PIL.Image.ANTIALIAS)\n",
    "\n",
    "        # normalize each channel     \n",
    "#         arr = np.array(band4image)\n",
    "        arr = np.array(band3image)\n",
    "    \n",
    "#         # average red and yellow channels, orange\n",
    "#         arr[...,0] = (arr[...,0] + arr[...,3])/2.0\n",
    "#         arr = arr[...,:3]\n",
    "        \n",
    "        # arr = np.array(band3image)\n",
    "        # print('arr shape',arr.shape)\n",
    "        # if index==0: print(index,'hist before',histogram(arr))\n",
    "        \n",
    "#         arr = normalize(arr)\n",
    "#         arr = standardize(arr)\n",
    "#         arr = equalize(arr)\n",
    "        \n",
    "#         # average red and yellow channels, orange\n",
    "#         arr[...,0] = (arr[...,0] + arr[...,3])/2.0\n",
    "#         arr = arr[...,:3]\n",
    "                \n",
    "        # if index==0: print(index,'hist after',histogram(arr))\n",
    "        band3image = PIL.Image.fromarray(arr.astype('uint8'),'RGB')\n",
    "#         band4image = PIL.Image.fromarray(arr.astype('uint8'),'RGBA')\n",
    "\n",
    "        # histogram equalize each channel\n",
    "        \n",
    "#         arr = np.array(band4image)\n",
    "#         # print('arr',arr.shape)\n",
    "#         # if index==0: print(index,'hist before',histogram(arr))\n",
    "#         arr = equalize(arr)\n",
    "#         # if index==0: print(index,'hist after',histogram(arr))\n",
    "#         band4image = PIL.Image.fromarray(arr.astype('uint8'),'RGBA')\n",
    "        \n",
    "#         return band4image\n",
    "        return band3image\n",
    "#         return arr\n",
    "\n",
    "#         band3image = PIL.Image.new(\"RGB\", band4image.size, (255, 255, 255))\n",
    "#         band3image.paste(band4image, mask=band4image.split()[3]) \n",
    "#         band3image = band3image.resize((image_size,image_size), PIL.Image.ANTIALIAS)\n",
    "#         return band3image\n",
    "   \n",
    "    \n",
    "    def _load_multilabel_target(self, index):\n",
    "        y = self.images_df.iloc[index].Target.split(' ')\n",
    "#         print(y)\n",
    "        try:\n",
    "            yl = list(map(int, y))\n",
    "        except:\n",
    "            yl = []\n",
    "        return yl\n",
    "    \n",
    "        \n",
    "    def collate_func(self, batch):\n",
    "        labels = None\n",
    "        images = [x[0] for x in batch]\n",
    "        \n",
    "        if self.train_mode:\n",
    "            labels = [x[1] for x in batch]\n",
    "            labels_one_hot  = self.mlb.fit_transform(labels)\n",
    "            labels = torch.FloatTensor(labels_one_hot)\n",
    "            \n",
    "        \n",
    "        # return torch.stack(images)[:,:4,:,:], labels\n",
    "        return torch.stack(images), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imean = (0.08069, 0.05258, 0.05487)\n",
    "istd = (0.13704, 0.10145, 0.15313)\n",
    "\n",
    "train_aug = A.Compose([\n",
    "#                         A.Rotate((0,30),p=0.75),\n",
    "                        A.RandomRotate90(p=1),\n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.ShiftScaleRotate(p=0.9),\n",
    "#                         A.RandomBrightness(0.05),\n",
    "#                         A.RandomContrast(0.05),\n",
    "                        A.Normalize(mean=imean, std=istd,max_pixel_value=255.)\n",
    "                        ])\n",
    "\n",
    "test_aug = A.Compose([\n",
    "                        A.Normalize(mean=imean, std=istd, max_pixel_value=255.)\n",
    "                        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_transforms_train = transforms.Compose([\n",
    "#     transforms.Resize(size=final_size),\n",
    "#     # transforms.RandomResizedCrop(size=224),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     transforms.RandomVerticalFlip(p=0.5),\n",
    "# #     transforms.RandomRotation(degrees=45),\n",
    "#     transforms.RandomAffine(degrees=45, translate=(0.1,0.1), shear=10, scale=(0.9,1.1)),\n",
    "    transforms.ToTensor()\n",
    "#     transforms.Normalize(mean=[0.456]*4, std=[0.224]*4)\n",
    "])\n",
    "\n",
    "composed_transforms_test = transforms.Compose([\n",
    "#     transforms.Resize(size=final_size),\n",
    "    transforms.ToTensor()\n",
    "#     transforms.Normalize(mean=[0.456]*4, std=[0.224]*4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 1e-5\n",
    "gpu_id = 0\n",
    "\n",
    "thresh = 0.1\n",
    "\n",
    "# save_dir_root = os.path.join(os.path.dirname(os.path.abspath(__file__)))\n",
    "# exp_name = os.path.dirname(os.path.abspath(__file__)).split('/')[-1]\n",
    "\n",
    "save_dir_root = './'\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 0 \n",
      "['ENSG00000000460_24451_224_G2_1_blue.jpg', 'ENSG00000000003_4109_24_H11_1_red.jpg', 'ENSG00000000003_4109_23_H11_1_blue.jpg', 'ENSG00000000003_4109_24_H11_1_blue.jpg', 'ENSG00000000003_4109_24_H11_2_blue.jpg', 'ENSG00000000003_4109_23_H11_1_red.jpg', 'ENSG00000000003_4109_24_H11_1_yellow.jpg', 'ENSG00000000003_4109_23_H11_1_yellow.jpg', 'ENSG00000000003_4109_24_H11_2_red.jpg', 'ENSG00000000003_4109_23_H11_1_green.jpg', 'ENSG00000000003_4109_24_H11_2_green.jpg', 'ENSG00000000003_4109_24_H11_1_green.jpg', 'ENSG00000000003_4109_24_H11_2_yellow.jpg', 'ENSG00000000003_4109_23_H11_2_red.jpg', 'ENSG00000000003_4109_23_H11_2_blue.jpg'] 311022\n"
     ]
    }
   ],
   "source": [
    "fold = -1\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    print('Using GPU: {} '.format(gpu_id))\n",
    "    torch.cuda.set_device(device=gpu_id)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "file_list_x = [f for f in listdir(PATH_TO_EXTERNAL2) if isfile(join(PATH_TO_EXTERNAL2, f))]\n",
    "print(file_list_x[:15],len(file_list_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_xx = MultiBandMultiLabelDataset(dxx, \n",
    "                                  base_path=PATH_TO_EXTERNAL2,\n",
    "#                                   augmentator=test_aug,\n",
    "                                  image_transform=composed_transforms_test,\n",
    "                                  external=2)\n",
    "\n",
    "xxloader = DataLoader(db_xx, collate_fn=db_xx.collate_func,\n",
    "                         batch_size=1, shuffle=False,\n",
    "                         num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ./external_data3/ENSG00000000003_4109_24_H11_1\n",
      "1000 ./external_data3/ENSG00000008394_44840_559_C9_2\n",
      "2000 ./external_data3/ENSG00000023572_57224_980_B6_3\n",
      "3000 ./external_data3/ENSG00000047579_29615_511_B1_1\n",
      "4000 ./external_data3/ENSG00000060069_70389_1746_A7_17_cr5954c69c25641\n",
      "5000 ./external_data3/ENSG00000067225_19421_611_C7_1\n",
      "6000 ./external_data3/ENSG00000072952_8704_47_H1_2\n",
      "7000 ./external_data3/ENSG00000078053_19828_242_E7_2\n",
      "8000 ./external_data3/ENSG00000083544_34925_942_C1_1\n",
      "9000 ./external_data3/ENSG00000088538_37543_428_C2_1\n",
      "10000 ./external_data3/ENSG00000092621_24031_387_A4_1\n",
      "11000 ./external_data3/ENSG00000100105_47893_722_H9_2\n",
      "12000 ./external_data3/ENSG00000100749_17929_117_B1_2\n",
      "13000 ./external_data3/ENSG00000101940_913_76_B2_2\n",
      "14000 ./external_data3/ENSG00000103423_44229_964_F1_1\n",
      "15000 ./external_data3/ENSG00000104980_43052_si25_E6_8\n",
      "16000 ./external_data3/ENSG00000106028_2866_35_B11_1\n",
      "17000 ./external_data3/ENSG00000107937_56468_913_G8_2\n",
      "18000 ./external_data3/ENSG00000109606_47047_725_B8_1\n",
      "19000 ./external_data3/ENSG00000111424_47740_714_B3_3\n",
      "20000 ./external_data3/ENSG00000112984_36910_570_G8_2\n",
      "21000 ./external_data3/ENSG00000114867_28487_281_D7_1\n",
      "22000 ./external_data3/ENSG00000116171_27135_604_H9_1\n",
      "23000 ./external_data3/ENSG00000117751_27452_231_C4_1\n",
      "24000 ./external_data3/ENSG00000119878_56765_956_E3_3\n",
      "25000 ./external_data3/ENSG00000121964_36694_408_H9_1\n",
      "26000 ./external_data3/ENSG00000123989_35123_374_D4_1\n",
      "27000 ./external_data3/ENSG00000125651_22793_222_B12_1\n",
      "28000 ./external_data3/ENSG00000127124_5728_1248_A3_4\n",
      "29000 ./external_data3/ENSG00000129116_35905_404_E2_2\n",
      "30000 ./external_data3/ENSG00000130766_18191_151_F12_2\n",
      "31000 ./external_data3/ENSG00000132467_35655_1685_F12_2\n",
      "32000 ./external_data3/ENSG00000134056_35802_383_G10_3\n",
      "33000 ./external_data3/ENSG00000135316_41275_1041_H9_1\n",
      "34000 ./external_data3/ENSG00000136451_27520_279_D10_1\n",
      "35000 ./external_data3/ENSG00000137486_49318_682_C11_2\n",
      "36000 ./external_data3/ENSG00000138496_66708_1366_C12_4\n",
      "37000 ./external_data3/ENSG00000140105_5573_110_A1_2\n",
      "38000 ./external_data3/ENSG00000141522_10005_921_B9_2\n",
      "39000 ./external_data3/ENSG00000143322_1866_59_G5_1\n",
      "40000 ./external_data3/ENSG00000144579_62654_1294_C9_1\n",
      "41000 ./external_data3/ENSG00000146112_51000_761_E9_2\n",
      "42000 ./external_data3/ENSG00000147862_3956_27_H11_2\n",
      "43000 ./external_data3/ENSG00000149972_39492_462_F6_2\n",
      "44000 ./external_data3/ENSG00000152443_68553_1394_A9_1\n",
      "45000 ./external_data3/ENSG00000154370_43879_771_H1_1\n",
      "46000 ./external_data3/ENSG00000156689_65454_1559_F7_1\n",
      "47000 ./external_data3/ENSG00000158711_28863_295_B11_1\n",
      "48000 ./external_data3/ENSG00000160298_35111_624_G12_2\n",
      "49000 ./external_data3/ENSG00000162302_8649_635_D3_1\n",
      "50000 ./external_data3/ENSG00000163322_37654_750_D2_2\n",
      "51000 ./external_data3/ENSG00000164062_29702_365_B3_1\n",
      "52000 ./external_data3/ENSG00000164916_18864_150_F8_1\n",
      "53000 ./external_data3/ENSG00000165899_40364_418_E10_1\n",
      "54000 ./external_data3/ENSG00000166888_1861_26_A4_2\n",
      "55000 ./external_data3/ENSG00000167861_31406_820_A10_3\n",
      "56000 ./external_data3/ENSG00000168795_21521_1219_A10_2\n",
      "57000 ./external_data3/ENSG00000169955_3203_61_H10_1\n",
      "58000 ./external_data3/ENSG00000171204_14480_598_G1_1\n",
      "59000 ./external_data3/ENSG00000172465_57345_991_C9_1\n",
      "60000 ./external_data3/ENSG00000173905_1677_13_C10_1\n",
      "61000 ./external_data3/ENSG00000175573_45938_579_D11_1\n",
      "62000 ./external_data3/ENSG00000177469_49838_751_B9_5\n",
      "63000 ./external_data3/ENSG00000179119_47957_756_E3_6\n",
      "64000 ./external_data3/ENSG00000181019_7308_10_A7_1\n",
      "65000 ./external_data3/ENSG00000182985_37266_640_E3_1\n",
      "66000 ./external_data3/ENSG00000184575_57602_1208_D9_2\n",
      "67000 ./external_data3/ENSG00000185946_52434_865_H1_1\n",
      "68000 ./external_data3/ENSG00000187954_59543_1218_C5_1\n",
      "69000 ./external_data3/ENSG00000196150_20853_190_F9_1\n",
      "70000 ./external_data3/ENSG00000197037_55127_911_G1_2\n",
      "71000 ./external_data3/ENSG00000198081_50758_1105_C2_2\n",
      "72000 ./external_data3/ENSG00000198934_3047_1746_G1_1\n",
      "73000 ./external_data3/ENSG00000205220_30225_322_F10_3\n",
      "74000 ./external_data3/ENSG00000214827_32040_1550_A1_3\n",
      "75000 ./external_data3/ENSG00000237172_62734_1159_G6_2\n",
      "76000 ./external_data3/ENSG00000254004_28806_587_B5_1\n",
      "77000 ./external_data3/ENSG00000267855_59251_1020_B9_4\n"
     ]
    }
   ],
   "source": [
    "id_list = []\n",
    "im_list = []\n",
    "y_list = []\n",
    "for i, (im, y) in enumerate(xxloader):\n",
    "#     if i % 1000 == 0: print(i,id)\n",
    "#     if i < 63914: continue\n",
    "    id = str(db_xx.images_df.Id[i])\n",
    "    im = im.cpu().detach().numpy()[0].transpose(1,2,0)*255\n",
    "#     print(im.shape,im.min(),im.mean(),im.max())\n",
    "    im = PIL.Image.fromarray(im.astype('uint8'),'RGB')\n",
    "    id = PATH_TO_EXTERNAL3 + id[15:]\n",
    "    im.save(id+'.png',\"PNG\")\n",
    "#     y = y.cpu().detach().numpy()\n",
    "#     id_list.append(id)\n",
    "#     im_list.append(im)\n",
    "#     y_list.append(y)\n",
    "    if i % 1000 == 0: print(i,id)\n",
    "#     if i % 1000 == 0: print(i,id,s,y)\n",
    "#     if i==10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
