{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = 'irv2_b8'\n",
    "seed = 723\n",
    "fold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "nfold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights from this model\n",
    "mname0 = 'irv2_b7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import timeit\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import random\n",
    "import PIL\n",
    "import pathlib\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau, StepLR\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torchvision\n",
    "\n",
    "from skimage.exposure import histogram, equalize_hist, equalize_adapthist\n",
    "from skimage.morphology import binary_dilation\n",
    "\n",
    "import pretrainedmodels\n",
    "from xception import xception\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from scipy.special import logit\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from sklearn.metrics import jaccard_similarity_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import multiprocessing\n",
    "import threading\n",
    "\n",
    "from dataloaders import utils\n",
    "from dataloaders import custom_transforms as tr\n",
    "\n",
    "# from losses import CombinedLoss, BCELoss2d\n",
    "from losses import FocalLoss, ThreeWayLoss\n",
    "import lovasz_losses as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7114b9f3da03d4688ecfdecd7c7008a0be0c8004",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 512 512 512\n"
     ]
    }
   ],
   "source": [
    "ori_size = 512\n",
    "up_size = 512\n",
    "image_size = 512\n",
    "final_size = 512\n",
    "\n",
    "interp = cv2.INTER_AREA\n",
    "# methods=[(\"area\", cv2.INTER_AREA), \n",
    "#          (\"nearest\", cv2.INTER_NEAREST), \n",
    "#          (\"linear\", cv2.INTER_LINEAR), \n",
    "#          (\"cubic\", cv2.INTER_CUBIC), \n",
    "#          (\"lanczos4\", cv2.INTER_LANCZOS4)]\n",
    "\n",
    "y_pad = image_size - up_size\n",
    "y_min_pad = int(y_pad / 2)\n",
    "y_max_pad = y_pad - y_min_pad\n",
    "\n",
    "x_pad = image_size - up_size\n",
    "x_min_pad = int(x_pad / 2)\n",
    "x_max_pad = x_pad - x_min_pad\n",
    "\n",
    "print(ori_size, up_size, image_size, final_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "\n",
    "PATH_TO_TRAIN = PATH + 'train/'\n",
    "PATH_TO_TEST = PATH + 'test/'\n",
    "PATH_TO_TARGET = PATH + 'train.csv'\n",
    "PATH_TO_SUB = PATH + 'sample_submission.csv'\n",
    "\n",
    "clusters = pd.read_csv('cluster4_folds.csv')\n",
    "folds = dict(zip(clusters.Id,clusters.cluster4))\n",
    "\n",
    "LABEL_MAP = {\n",
    "0: \"Nucleoplasm\" ,\n",
    "1: \"Nuclear membrane\"   ,\n",
    "2: \"Nucleoli\"   ,\n",
    "3: \"Nucleoli fibrillar center\",   \n",
    "4: \"Nuclear speckles\"   ,\n",
    "5: \"Nuclear bodies\"   ,\n",
    "6: \"Endoplasmic reticulum\"   ,\n",
    "7: \"Golgi apparatus\"  ,\n",
    "8: \"Peroxisomes\"   ,\n",
    "9:  \"Endosomes\"   ,\n",
    "10: \"Lysosomes\"   ,\n",
    "11: \"Intermediate filaments\"  , \n",
    "12: \"Actin filaments\"   ,\n",
    "13: \"Focal adhesion sites\"  ,\n",
    "14: \"Microtubules\"   ,\n",
    "15: \"Microtubule ends\"   ,\n",
    "16: \"Cytokinetic bridge\"   ,\n",
    "17: \"Mitotic spindle\"  ,\n",
    "18: \"Microtubule organizing center\",  \n",
    "19: \"Centrosome\",\n",
    "20: \"Lipid droplets\"   ,\n",
    "21: \"Plasma membrane\"  ,\n",
    "22: \"Cell junctions\"   ,\n",
    "23: \"Mitochondria\"   ,\n",
    "24: \"Aggresome\"   ,\n",
    "25: \"Cytosol\" ,\n",
    "26: \"Cytoplasmic bodies\",\n",
    "27: \"Rods & rings\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'imagenet+5k': {'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn92_extra-b040e4a9b.pth', 'input_space': 'RGB', 'input_size': [3, 224, 224], 'input_range': [0, 1], 'mean': [0.48627450980392156, 0.4588235294117647, 0.40784313725490196], 'std': [0.23482446870963955, 0.23482446870963955, 0.23482446870963955], 'num_classes': 1000}}\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.pretrained_settings['dpn92'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "95e82b2a7155377310f1d743dd8b077f99cba657",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Target\n",
      "Id                                           \n",
      "00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
      "000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
      "000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
      "000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
      "001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18\n",
      "(31072, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH_TO_TARGET)\n",
    "df.set_index('Id',inplace=True)\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "95e82b2a7155377310f1d743dd8b077f99cba657",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Predicted\n",
      "Id                                             \n",
      "00008af0-bad0-11e8-b2b8-ac1f6b6435d0          0\n",
      "0000a892-bacf-11e8-b2b8-ac1f6b6435d0          0\n",
      "0006faa6-bac7-11e8-b2b7-ac1f6b6435d0          0\n",
      "0008baca-bad7-11e8-b2b9-ac1f6b6435d0          0\n",
      "000cce7e-bad4-11e8-b2b8-ac1f6b6435d0          0\n",
      "(11702, 1)\n"
     ]
    }
   ],
   "source": [
    "file_list = list(df.index.values)\n",
    "\n",
    "ss = pd.read_csv(PATH_TO_SUB)\n",
    "ss.set_index('Id',inplace=True)\n",
    "print(ss.head())\n",
    "print(ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "95e82b2a7155377310f1d743dd8b077f99cba657",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', '000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', '000a9596-bbc4-11e8-b2bc-ac1f6b6435d0'] ./train/ 31072\n",
      "['00008af0-bad0-11e8-b2b8-ac1f6b6435d0', '0000a892-bacf-11e8-b2b8-ac1f6b6435d0', '0006faa6-bac7-11e8-b2b7-ac1f6b6435d0'] ./test/ 11702\n"
     ]
    }
   ],
   "source": [
    "test_file_list = list(ss.index.values)\n",
    "print(file_list[:3], PATH_TO_TRAIN, len(file_list))\n",
    "print(test_file_list[:3], PATH_TO_TEST, len(test_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_histogram_equalization(image, number_bins=256):\n",
    "    # from http://www.janeriksolem.net/2009/06/histogram-equalization-with-python-and.html\n",
    "\n",
    "    # get image histogram\n",
    "    image_histogram, bins = np.histogram(image.flatten(), number_bins, density=True)\n",
    "    cdf = image_histogram.cumsum() # cumulative distribution function\n",
    "    cdf = 255 * cdf / cdf[-1] # normalize\n",
    "\n",
    "    # use linear interpolation of cdf to find new pixel values\n",
    "    image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n",
    "\n",
    "    # return image_equalized.reshape(image.shape), cdf\n",
    "    return image_equalized.reshape(image.shape)\n",
    "\n",
    "def equalize(arr):\n",
    "    arr = arr.astype('float')\n",
    "    # usually do not touch the alpha channel\n",
    "    # but here we do since it is yellow\n",
    "    for i in range(4):\n",
    "        # arr[...,i] = 255 * equalize_hist(arr[...,i])\n",
    "        arr[...,i] = image_histogram_equalization(arr[...,i])                                  \n",
    "    return arr\n",
    "\n",
    "def normalize(arr, q=0.01):\n",
    "    arr = arr.astype('float')\n",
    "    # usually do not touch the alpha channel\n",
    "    # but here we do since it is yellow\n",
    "    # print('arr before',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    for i in range(arr.shape[-1]):\n",
    "        # arr[...,i] = 255 * equalize_hist(arr[...,i])\n",
    "        ai = arr[...,i]\n",
    "        # print('ai ' + str(i) + ' before',i,ai.shape,ai.min(),ai.mean(),ai.max())\n",
    "        qlow = np.percentile(ai,100*q)\n",
    "        qhigh = np.percentile(ai,100*(1.0-q))\n",
    "        if qlow == qhigh:\n",
    "            arr[...,i] = 0.\n",
    "        else:\n",
    "            arr[...,i] = 255.*(np.clip(ai,qlow,qhigh) - qlow)/(qhigh - qlow)                              \n",
    "        # print('ai ' + str(i) + ' after',i,ai.shape,ai.min(),ai.mean(),ai.max())\n",
    "    # print('arr after',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    return arr\n",
    "\n",
    "\n",
    "class MultiBandMultiLabelDataset(Dataset):\n",
    "    \n",
    "#     BANDS_NAMES = ['_red.png','_green.png','_blue.png','_yellow.png']\n",
    "    BANDS_NAMES = ['_red.png','_green.png','_blue.png']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_df)\n",
    "    \n",
    "    def __init__(self, images_df, \n",
    "                 base_path, \n",
    "                 image_transform=None, \n",
    "                 augmentator=None,\n",
    "                 train_mode=True    \n",
    "                ):\n",
    "        if not isinstance(base_path, pathlib.Path):\n",
    "            base_path = pathlib.Path(base_path)\n",
    "            \n",
    "        self.images_df = images_df.reset_index()\n",
    "        self.image_transform = image_transform\n",
    "        self.augmentator = augmentator\n",
    "        self.images_df.Id = self.images_df.Id.apply(lambda x: base_path / x)\n",
    "        self.mlb = MultiLabelBinarizer(classes=list(LABEL_MAP.keys()))\n",
    "        self.train_mode = train_mode\n",
    "        self.cache = {}\n",
    "                                 \n",
    "    def __getitem__(self, index):\n",
    "        # print('index class',index.__class__)\n",
    "        if isinstance(index, torch.Tensor): index = index.item()\n",
    "        if index in self.cache: \n",
    "            X, y = self.cache[index]\n",
    "        else:\n",
    "            y = None\n",
    "            X = self._load_multiband_image(index)\n",
    "            if self.train_mode:\n",
    "                y = self._load_multilabel_target(index)\n",
    "            self.cache[index] = (X,y)\n",
    "        \n",
    "        # augmentator can be for instance imgaug augmentation object\n",
    "        if self.augmentator is not None:\n",
    "            X = self.augmentator(X)\n",
    "           \n",
    "        if self.image_transform is not None:\n",
    "            X = self.image_transform(X)\n",
    "        \n",
    "        return X, y \n",
    "        \n",
    "    def _load_multiband_image(self, index):\n",
    "        row = self.images_df.iloc[index]\n",
    "        image_bands = []\n",
    "        for band_name in self.BANDS_NAMES:\n",
    "            p = str(row.Id.absolute()) + band_name\n",
    "            pil_channel = PIL.Image.open(p)\n",
    "            image_bands.append(pil_channel)\n",
    "            \n",
    "        # pretend its a RBGA image to support 4 channels\n",
    "#         band4image = PIL.Image.merge('RGBA', bands=image_bands)\n",
    "        band3image = PIL.Image.merge('RGB', bands=image_bands)\n",
    "\n",
    "        # normalize each channel     \n",
    "#         arr = np.array(band4image)\n",
    "        arr = np.array(band3image)\n",
    "#         # average red and yellow channels, orange\n",
    "#         arr[...,0] = (arr[...,0] + arr[...,3])/2.0\n",
    "#         arr = arr[...,:3]\n",
    "        \n",
    "        # arr = np.array(band3image)\n",
    "        # print('arr shape',arr.shape)\n",
    "        # if index==0: print(index,'hist before',histogram(arr))\n",
    "        arr = normalize(arr)\n",
    "        # if index==0: print(index,'hist after',histogram(arr))\n",
    "        band3image = PIL.Image.fromarray(arr.astype('uint8'),'RGB')\n",
    "#         band4image = PIL.Image.fromarray(arr.astype('uint8'),'RGBA')\n",
    "\n",
    "        # histogram equalize each channel\n",
    "        \n",
    "#         arr = np.array(band4image)\n",
    "#         # print('arr',arr.shape)\n",
    "#         # if index==0: print(index,'hist before',histogram(arr))\n",
    "#         arr = equalize(arr)\n",
    "#         # if index==0: print(index,'hist after',histogram(arr))\n",
    "#         band4image = PIL.Image.fromarray(arr.astype('uint8'),'RGBA')\n",
    "        \n",
    "#         return band4image\n",
    "        return band3image\n",
    "\n",
    "#         band3image = PIL.Image.new(\"RGB\", band4image.size, (255, 255, 255))\n",
    "#         band3image.paste(band4image, mask=band4image.split()[3]) \n",
    "#         band3image = band3image.resize((image_size,image_size), PIL.Image.ANTIALIAS)\n",
    "#         return band3image\n",
    "   \n",
    "    \n",
    "    def _load_multilabel_target(self, index):\n",
    "        return list(map(int, self.images_df.iloc[index].Target.split(' ')))\n",
    "    \n",
    "        \n",
    "    def collate_func(self, batch):\n",
    "        labels = None\n",
    "        images = [x[0] for x in batch]\n",
    "        \n",
    "        if self.train_mode:\n",
    "            labels = [x[1] for x in batch]\n",
    "            labels_one_hot  = self.mlb.fit_transform(labels)\n",
    "            labels = torch.FloatTensor(labels_one_hot)\n",
    "            \n",
    "        \n",
    "        # return torch.stack(images)[:,:4,:,:], labels\n",
    "        return torch.stack(images), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(object):\n",
    "    \"\"\"Class encapsulating a batch before and after augmentation.\"\"\"\n",
    "    def __init__(self, identifiers, images, targets):\n",
    "        self.identifiers = identifiers\n",
    "        self.images = images\n",
    "        self.images_aug = None\n",
    "        self.targets = targets\n",
    "        self.masks = None\n",
    "\n",
    "class ImageLoader(object):\n",
    "    \"\"\"Class to load batches in the background.\"\"\"\n",
    "\n",
    "    def __init__(self, load_batch_func, nb_workers=1, queue_size=50, threaded=True):\n",
    "        self.queue = multiprocessing.Queue(queue_size)\n",
    "        self.workers = []\n",
    "        for i in range(nb_workers):\n",
    "            if threaded:\n",
    "                worker = threading.Thread(target=self._load_batches, args=(load_batch_func, self.queue))\n",
    "            else:\n",
    "                worker = multiprocessing.Process(target=self._load_batches, args=(load_batch_func, self.queue))\n",
    "            worker.daemon = True\n",
    "            worker.start()\n",
    "            self.workers.append(worker)\n",
    "\n",
    "    def _load_batches(self, load_batch_func, queue):\n",
    "        while True:\n",
    "            queue.put(pickle.dumps(load_batch_func(), protocol=-1))\n",
    "\n",
    "class BackgroundAugmenter(object):\n",
    "    \"\"\"Class to augment batches in the background (while training on\n",
    "    the GPU).\"\"\"\n",
    "    def __init__(self, augseq, queue_source, nb_workers, queue_size=50, threaded=False):\n",
    "        assert 0 < queue_size <= 10000\n",
    "        self.augseq = augseq\n",
    "        self.queue_source = queue_source\n",
    "        self.queue_result = multiprocessing.Queue(queue_size)\n",
    "        self.workers = []\n",
    "        for i in range(nb_workers):\n",
    "            augseq.reseed()\n",
    "            if threaded:\n",
    "                worker = threading.Thread(target=self._augment_images_worker, args=(self.augseq, self.queue_source, self.queue_result))\n",
    "            else:\n",
    "                worker = multiprocessing.Process(target=self._augment_images_worker, args=(self.augseq, self.queue_source, self.queue_result))\n",
    "            worker.daemon = True\n",
    "            worker.start()\n",
    "            self.workers.append(worker)\n",
    "\n",
    "    def get_batch(self):\n",
    "        \"\"\"Returns a batch from the queue of augmented batches.\"\"\"\n",
    "        batch_str = self.queue_result.get()\n",
    "        batch = pickle.loads(batch_str)\n",
    "        return batch\n",
    "\n",
    "    def _augment_images_worker(self, augseq, queue_source, queue_result):\n",
    "        \"\"\"Worker function that endlessly queries the source queue (input\n",
    "        batches), augments batches in it and sends the result to the output\n",
    "        queue.\"\"\"\n",
    "        while True:\n",
    "            # wait for a new batch in the source queue and load it\n",
    "            batch_str = queue_source.get()\n",
    "            batch = pickle.loads(batch_str)\n",
    "\n",
    "#             # augment the batch\n",
    "#             if batch.images is not None and batch.masks is not None:\n",
    "#                 augseq_det = augseq.to_deterministic()\n",
    "#                 batch.images_aug = augseq_det.augment_images(batch.images)\n",
    "#                 batch.masks_aug = augseq_det.augment_images(batch.masks)\n",
    "#             elif batch.images is not None:\n",
    "#                 batch.images_aug = augseq.augment_images(batch.images)\n",
    "#             elif batch.masks is not None:\n",
    "#                 batch.masks_aug = augseq.augment_images(batch.masks)\n",
    "\n",
    "            if batch.images is not None:\n",
    "                batch.images_aug = augseq.augment_images(batch.images)\n",
    "\n",
    "            # send augmented batch to output queue\n",
    "            queue_result.put(pickle.dumps(batch, protocol=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize image augmentation cascade\n",
    "rarely = lambda aug: iaa.Sometimes(0.1, aug)\n",
    "sometimes = lambda aug: iaa.Sometimes(0.25, aug)\n",
    "often = lambda aug: iaa.Sometimes(0.75, aug)\n",
    "seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "        iaa.Flipud(0.5), # vertically flip 50% of all images\n",
    "#         rarely(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "#         often(iaa.Crop(percent=(0, 0.1))), # crop images by 0-10% of their height/width\n",
    "#         sometimes(iaa.GaussianBlur((0, 3.0))), # blur images with a sigma between 0 and 3.0\n",
    "#         sometimes(iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5))), # sharpen images\n",
    "#         sometimes(iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0))), # emboss images\n",
    "#         # search either for all edges or for directed edges\n",
    "#         rarely(iaa.Sometimes(0.5,\n",
    "#             iaa.EdgeDetect(alpha=(0, 0.7)),\n",
    "#             iaa.DirectedEdgeDetect(alpha=(0, 0.7), direction=(0.0, 1.0)),\n",
    "#         )),\n",
    "#         often(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.2), per_channel=0.5)), # add gaussian noise to images\n",
    "#         often(iaa.Dropout((0.0, 0.1), per_channel=0.5)), # randomly remove up to 10% of the pixels\n",
    "#         # rarely(iaa.Invert(0.25, per_channel=True)), # invert color channels\n",
    "#         often(iaa.Add((-10, 10), per_channel=0.5)), # change brightness of images (by -10 to 10 of original value)\n",
    "#         often(iaa.Multiply((0.5, 1.5), per_channel=0.25)), # change brightness of images (50-150% of original value)\n",
    "#         often(iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5)), # improve or worsen the contrast\n",
    "#         # sometimes(iaa.Grayscale(alpha=(0.0, 1.0))),\n",
    "#         often(iaa.Affine(\n",
    "#             scale={\"x\": (0.6, 1.4), \"y\": (0.6, 1.4)}, # scale images to 60-140% of their size, individually per axis\n",
    "#             translate_percent={\"x\": (-0.3, 0.3), \"y\": (-0.3, 0.3)}, # translate by -30 to +30% percent (per axis)\n",
    "#             rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "#             shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "#             order=[0, 1], # use any of scikit-image's interpolation methods\n",
    "#             cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "#             mode=[\"constant\", \"edge\"] # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "#         )),\n",
    "#         sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)) # apply elastic transformations with random strengths\n",
    "    ],\n",
    "    random_order=True # do all of the above in random order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_string(module):\n",
    "    lines = [\n",
    "        \"\",\n",
    "        \"List of model parameters:\",\n",
    "        \"=========================\",\n",
    "    ]\n",
    "\n",
    "    row_format = \"{name:<40} {shape:>20} ={total_size:>12,d}\"\n",
    "    params = list(module.named_parameters())\n",
    "    for name, param in params:\n",
    "        lines.append(row_format.format(\n",
    "            name=name,\n",
    "            shape=\" * \".join(str(p) for p in param.size()),\n",
    "            total_size=param.numel()\n",
    "        ))\n",
    "    lines.append(\"=\" * 75)\n",
    "    lines.append(row_format.format(\n",
    "        name=\"all parameters\",\n",
    "        shape=\"sum of above\",\n",
    "        total_size=sum(int(param.numel()) for name, param in params)\n",
    "    ))\n",
    "    lines.append(\"\")\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_transforms_train = transforms.Compose([\n",
    "    transforms.Resize(size=final_size),\n",
    "    # transforms.RandomResizedCrop(size=224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=45),\n",
    "    # tr.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    # tr.Normalize(mean=(0.485), std=(0.229)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.456]*4, std=[0.224]*4)\n",
    "])\n",
    "\n",
    "composed_transforms_test = transforms.Compose([\n",
    "    transforms.Resize(size=final_size),\n",
    "    # tr.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    # tr.Normalize(mean=(0.485), std=(0.229)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.456]*4, std=[0.224]*4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# model and main parameter settings #\n",
    "#####################################\n",
    "\n",
    "%run 'inceptionresnetv2_b8.ipynb'\n",
    "\n",
    "device = \"cuda\"\n",
    "# device = \"cpu\"\n",
    "\n",
    "p = OrderedDict()  # Parameters to include in report\n",
    "p['trainBatch'] = 24  # Training batch size\n",
    "p['testBatch'] = 24  # Testing batch size\n",
    "\n",
    "nEpochs = 24  # Number of epochs for training\n",
    "resume_epoch = 0  # Default is 0, change if want to resume\n",
    "\n",
    "p['lr'] = 3e-4  # Learning rate\n",
    "p['step_size'] = 8\n",
    "p['gamma'] = 0.1\n",
    "p['wd'] = 1e-4  # Weight decay\n",
    "p['momentum'] = 0.9  # Momentum\n",
    "p['epoch_size'] = 15 # How many epochs to change learning rate\n",
    "p['patience'] = 30 # epochs to wait for early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./iv3_b6/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 28\n",
    "gsize = 14\n",
    "gpct = 95.\n",
    "gstd = 0.1\n",
    "gthresh = -2.0\n",
    "eps = 1e-5\n",
    "\n",
    "# save_dir_root = os.path.join(os.path.dirname(os.path.abspath(__file__)))\n",
    "# exp_name = os.path.dirname(os.path.abspath(__file__)).split('/')[-1]\n",
    "\n",
    "save_dir_root = './'\n",
    "\n",
    "# save_dir = os.path.join(save_dir_root, 'run', 'run_' + str(run_id))\n",
    "save_dir = save_dir_root + mname + '/'\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "print(save_dir)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "iv3_b6 fold 2\n",
      "**************************************************\n",
      "Number of parameters: 21,852,066\n",
      "Initializing weights from iv3_b5/best_2.pth\n",
      "Using GPU: 0 \n",
      "Training on 19368 and validating on 11704\n",
      "Sampling weights:\n",
      "[   2.3482   31.1383    8.8519   23.6195   18.641    12.9552   32.0662\n",
      "   11.6255  807.      922.2857 1760.7273   31.803    47.1241   69.6691\n",
      "   29.1687 1291.2      56.4665  110.0455   33.5667   23.7062  312.3871\n",
      "    7.0971   37.5349   10.802   123.3631    3.4499   94.478  3873.6   ]\n",
      "Image size: 512\n",
      "Batch size: 24\n",
      "Batches per epoch: 807\n",
      "Epochs: 24\n",
      "Loss: BCEWithLogitsLoss()\n",
      "\n",
      "learning rate = 0.000300\n",
      "epoch 0 training class proportions:\n",
      "[0.3134 0.0415 0.102  0.0501 0.0499 0.0755 0.0553 0.0568 0.0428 0.0623 0.0425\n",
      " 0.0425 0.0423 0.0425 0.0542 0.0427 0.0698 0.0431 0.0513 0.0442 0.0403 0.0926\n",
      " 0.0429 0.0579 0.0408 0.1834 0.0394 0.0374]\n",
      "epoch 0  train 1.5622  val 0.9092  delta -0.6530  f1 0.3982*  thresh 3.1  time 833s\n",
      "\n",
      "epoch 1 training class proportions:\n",
      "[0.3183 0.041  0.1012 0.049  0.0468 0.0755 0.0609 0.0546 0.043  0.0615 0.0421\n",
      " 0.0438 0.043  0.0408 0.0524 0.0431 0.0731 0.0434 0.0533 0.0413 0.0401 0.0906\n",
      " 0.0431 0.0573 0.0415 0.1864 0.04   0.0405]\n",
      "epoch 1  train 0.9730  val 0.8357  delta -0.1373  f1 0.4455*  thresh 3.6  time 822s\n",
      "\n",
      "epoch 2 training class proportions:\n",
      "[0.3207 0.0438 0.0983 0.0476 0.0493 0.0755 0.0581 0.0508 0.0411 0.059  0.0408\n",
      " 0.0451 0.0429 0.0416 0.0532 0.041  0.0671 0.0415 0.0527 0.0442 0.0421 0.0904\n",
      " 0.0424 0.0593 0.0416 0.1825 0.0416 0.0424]\n",
      "epoch 2  train 0.8278  val 0.7647  delta -0.0631  f1 0.5086*  thresh 3.9  time 823s\n",
      "\n",
      "epoch 3 training class proportions:\n",
      "[0.3127 0.043  0.1045 0.0469 0.0469 0.0757 0.0605 0.054  0.0432 0.0598 0.0419\n",
      " 0.0427 0.044  0.0428 0.052  0.0408 0.0693 0.0395 0.0518 0.0471 0.0418 0.0879\n",
      " 0.0429 0.0599 0.0414 0.1827 0.0391 0.0416]\n",
      "epoch 3  train 0.7414  val 0.7699  delta 0.0285  f1 0.5314*  thresh 4.1  time 824s\n",
      "\n",
      "epoch 4 training class proportions:\n",
      "[0.3091 0.042  0.1002 0.049  0.049  0.0763 0.0604 0.0537 0.0428 0.061  0.0423\n",
      " 0.0436 0.0425 0.0423 0.0508 0.0394 0.0673 0.0427 0.0495 0.0442 0.0419 0.09\n",
      " 0.041  0.061  0.0417 0.1852 0.0424 0.0424]\n",
      "epoch 4  train 0.6845  val 0.6924  delta 0.0080  f1 0.5217   thresh 4.3  time 821s\n",
      "\n",
      "epoch 5 training class proportions:\n",
      "[0.31   0.0433 0.1011 0.0469 0.0484 0.0751 0.0604 0.0494 0.0419 0.0635 0.0442\n",
      " 0.0423 0.0441 0.039  0.0531 0.0399 0.0679 0.042  0.0518 0.0414 0.0395 0.0928\n",
      " 0.0416 0.0574 0.0424 0.1874 0.0428 0.0408]\n",
      "epoch 5  train 0.6281  val 0.7253  delta 0.0971  f1 0.5456*  thresh 4.6  time 824s\n",
      "\n",
      "epoch 6 training class proportions:\n",
      "[0.3105 0.0398 0.1058 0.0504 0.0492 0.0782 0.0613 0.0532 0.0425 0.0629 0.0435\n",
      " 0.0439 0.0444 0.0414 0.0522 0.0446 0.0705 0.0433 0.0526 0.0424 0.0411 0.0918\n",
      " 0.0392 0.058  0.0421 0.1834 0.0395 0.0383]\n",
      "epoch 6  train 0.5895  val 0.6999  delta 0.1105  f1 0.5309   thresh 4.5  time 823s\n",
      "\n",
      "epoch 7 training class proportions:\n",
      "[0.3137 0.0394 0.1034 0.0505 0.0473 0.0806 0.0584 0.0519 0.0403 0.0612 0.0411\n",
      " 0.0445 0.0437 0.0437 0.0519 0.0409 0.0644 0.0398 0.0508 0.0422 0.0407 0.0909\n",
      " 0.0404 0.0624 0.0421 0.1868 0.0409 0.0425]\n",
      "epoch 7  train 0.5608  val 0.6714  delta 0.1106  f1 0.5812*  thresh 4.4  time 825s\n",
      "\n",
      "learning rate = 0.000030\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "for f in range(nfold):\n",
    "    \n",
    "    if f != fold: continue\n",
    "    \n",
    "    print('')\n",
    "    print('*'*50)\n",
    "    print(mname + ' fold ' + str(fold))\n",
    "    print('*'*50)\n",
    "    bname = mname+'/'+'best_'+str(fold)+'.pth'\n",
    "    \n",
    "    # Network definition\n",
    "    net = InceptionResnetV2    pw = torch.tensor([10.]).float().to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pw)\n",
    "(num_classes=28)\n",
    "    \n",
    "    print(\"Number of parameters:\",\"{:,}\".format(count_parameters(net)))\n",
    "    # print(p.status())\n",
    "\n",
    "    # classification loss\n",
    "    # criterion = utils.cross_entropy2d\n",
    "    # criterion = torch.nn.BCELoss()\n",
    "    # criterion = dice_loss\n",
    "    # criterion = BCELoss2d()\n",
    "    # criterion = CombinedLoss(is_weight=False).cuda()\n",
    "    # criterion = L.lovasz_hinge\n",
    "    # criterion = L.lovasz2_bce1\n",
    "    # criterion = L.lovasz_hinge\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "    # criterion = FocalLoss()\n",
    "    # criterion = ThreeWayLoss()\n",
    "\n",
    "    # segmentation loss\n",
    "    # criterion = L.lovasz_hinge\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    pw = torch.tensor([10.]).float().to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pw)\n",
    "    # criterion = F.smooth_l1_loss\n",
    "\n",
    "    if resume_epoch == 0:\n",
    "        if len(mname0):\n",
    "            bname0 = mname0+'/'+'best_'+str(fold)+'.pth'\n",
    "            print(f'Initializing weights from {bname0}')\n",
    "            # load best model\n",
    "            best = torch.load(bname0, map_location='cpu')\n",
    "            # print(best.keys())\n",
    "            net.load_state_dict(best, strict=False)\n",
    "    else:\n",
    "        print(f'Initializing weights from {bname}')\n",
    "        # load best model\n",
    "        best = torch.load(bname, map_location='cpu')\n",
    "        # print(best.keys())\n",
    "        net.load_state_dict(best, strict=False)\n",
    "\n",
    "    if gpu_id >= 0:\n",
    "        print('Using GPU: {} '.format(gpu_id))\n",
    "        torch.cuda.set_device(device=gpu_id)\n",
    "        # net.cuda()\n",
    "        net.train()\n",
    "        net.to(device)\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    # Logging into Tensorboard\n",
    "    # log_dir = os.path.join(save_dir, 'models', datetime.now().strftime('%b%d_%H-%M-%S') + '_' + socket.gethostname())\n",
    "    log_dir = os.path.join('tensorboard', mname + '_' + str(fold))\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # Use the following optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=p['lr'])\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=p['lr'], momentum=p['momentum'],\n",
    "#                           weight_decay=p['wd'])\n",
    "#     optimizer = torch.optim.Adadelta(net.parameters(), lr=1.0, rho=0.9, eps=1e-06,\n",
    "#                                      weight_decay=1e-6)\n",
    "    p['optimizer'] = str(optimizer)\n",
    "\n",
    "#     scheduler = LambdaLR(optimizer, lr_lambda=cyclic_lr)\n",
    "#     scheduler.base_lrs = list(map(lambda group: 1.0, optimizer.param_groups))  \n",
    "#     scheduler = ReduceLROnPlateau(optimizer, factor=0.2, patience=5, verbose=True, \n",
    "#                                   threshold=0.0, threshold_mode='abs')\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=p['step_size'], gamma=p['gamma'])\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    file_list_val = [f for f in file_list if folds[f]==fold]\n",
    "    file_list_train = [f for f in file_list if f not in file_list_val]\n",
    "    print('Training on ' + str(len(file_list_train)) + \\\n",
    "          ' and validating on ' + str(len(file_list_val)))\n",
    "    \n",
    " \n",
    "    db_train = MultiBandMultiLabelDataset(df.loc[file_list_train], \n",
    "                                          base_path=PATH_TO_TRAIN,\n",
    "                                          image_transform=composed_transforms_train)\n",
    "    db_val = MultiBandMultiLabelDataset(df.loc[file_list_val], \n",
    "                                        base_path=PATH_TO_TRAIN,\n",
    "                                        image_transform=composed_transforms_test)\n",
    "\n",
    "    # construct sampling weights as max of reciprocal class frequencies\n",
    "    ylist = [t.split(' ') for t in db_train.images_df.Target]\n",
    "    # print(ylist[:5])\n",
    "   \n",
    "    # build one-hot matrix\n",
    "    y = np.zeros((db_train.images_df.shape[0],28))\n",
    "    for i,l in enumerate(ylist):\n",
    "        for j in range(len(l)): y[i,int(l[j])] = 1.\n",
    "    # print(y[:20])\n",
    "\n",
    "    # sampling weights \n",
    "    w = 1.0/np.mean(y,axis=0)\n",
    "    # w = np.clip(w, 0., 1000.)\n",
    "    np.set_printoptions(precision=4,linewidth=80,suppress=True)\n",
    "    print('Sampling weights:')\n",
    "    print(w)\n",
    "\n",
    "    # replace 1s with weights in the one-hot matrix\n",
    "    for i,l in enumerate(ylist):\n",
    "        for j in range(len(l)): y[i,int(l[j])] = w[int(l[j])]\n",
    "    # print(y[:10])\n",
    "\n",
    "    # use maximum weight when there are multiple targets\n",
    "    samples_weight = np.amax(y,axis=1)\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'),\n",
    "                                    len(samples_weight))\n",
    "\n",
    "    trainloader = DataLoader(db_train, collate_fn=db_train.collate_func,\n",
    "                             batch_size=p['trainBatch'], sampler=sampler,\n",
    "                             num_workers=14)\n",
    "    valloader = DataLoader(db_val, collate_fn=db_train.collate_func,\n",
    "                           batch_size=p['testBatch'], shuffle=False,\n",
    "                          num_workers=14)\n",
    "    \n",
    "#     # function to generate batches within ImageLoader with no arguments\n",
    "#     def load_training_batch():\n",
    "#         examples_batch = random.sample(list(db_train.images_df.Id.values), p['trainBatch'])\n",
    "#         blist = [db_train[ex] for ex in examples_batch]\n",
    "#         images = [b[0] for b in blist]\n",
    "#         targets = [b[1] for b in blist]\n",
    "#         return Batch(identifiers=None, images=images, targets=targets)\n",
    "\n",
    "#     img_loader = ImageLoader(load_training_batch, nb_workers=6)\n",
    "#     bg_augmenter = BackgroundAugmenter(seq, img_loader.queue, nb_workers=8)\n",
    "\n",
    "    utils.generate_param_report(os.path.join(save_dir, mname + '.txt'), p)\n",
    "\n",
    "    # number of batches\n",
    "    num_img_tr = len(trainloader)\n",
    "    num_img_ts = len(valloader)\n",
    "    \n",
    "    print('Image size:', final_size)\n",
    "    print('Batch size:', p['trainBatch'])\n",
    "    print('Batches per epoch:', num_img_tr)\n",
    "    print('Epochs:', nEpochs)\n",
    "    print('Loss:', criterion)\n",
    "    # print('Learning rate: ', p['lr'])\n",
    "    print('')\n",
    "   \n",
    "    running_loss_tr = 0.0\n",
    "    running_loss_ts = 0.0\n",
    "    aveGrad = 0\n",
    "    bname = mname+'/'+'best_'+str(fold)+'.pth'\n",
    "    # print(\"Training Network\")\n",
    "    history = {}\n",
    "    history['epoch'] = []\n",
    "    history['train'] = []\n",
    "    history['val'] = []\n",
    "    history['delta'] = []\n",
    "    history['f1'] = []\n",
    "    history['time'] = []\n",
    "    best_val = -999\n",
    "    bad_epochs = 0\n",
    "    start_time = timeit.default_timer()\n",
    "    total_time = 0\n",
    "    prev_lr = 999\n",
    "\n",
    "    # Main Training and Testing Loop\n",
    "    for epoch in range(resume_epoch, nEpochs):\n",
    "\n",
    "#         if (epoch > 0) and (epoch % p['epoch_size'] == 0):\n",
    "#             lr_ = utils.lr_poly(p['lr'], epoch, nEpochs, 0.9)\n",
    "#             print('(poly lr policy) learning rate', lr_)\n",
    "#             print('')\n",
    "#             optimizer = optim.SGD(net.parameters(), lr=lr_, momentum=p['momentum'],\n",
    "#                                   weight_decay=p['wd'])\n",
    "\n",
    "        scheduler.step()\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        if lr != prev_lr: \n",
    "            print('learning rate = %.6f' % lr)\n",
    "            prev_lr = lr\n",
    "\n",
    "        net.train()\n",
    "        \n",
    "        train_loss = []\n",
    "        ns = 0\n",
    "        \n",
    "        # for ii in range(num_img_tr):\n",
    "        for ii, sample_batched in enumerate(trainloader):\n",
    "            \n",
    "            inputs, gts = sample_batched[0], sample_batched[1]\n",
    "#             inp = inputs.numpy()\n",
    "#             print('image stats', inp.shape, inp.min(), inp.mean(), inp.max())\n",
    "#             for j in range(4):\n",
    "#                 inpj = inp[:,j]\n",
    "#                 print('image ' + str(j) + ' stats', inpj.shape, inpj.min(), inpj.mean(),\n",
    "#                       inpj.max())\n",
    "            \n",
    "            # use thresholded green channel as ground truth mask for current classes\n",
    "            gi = inputs.numpy()[:,1].copy()\n",
    "#             print('gi stats', gi.shape, gi.min(), gi.mean(), gi.max())\n",
    "            bsize = gi.shape[0]\n",
    "            gmask = np.zeros((bsize, num_classes, gsize, gsize)).astype(int)\n",
    "            for jj in range(bsize):\n",
    "                gij = gi[jj]\n",
    "#                 print('gij before filter', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "#                 gij = gaussian_filter(gij,gstd)\n",
    "#                 print('gij after filter', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "                gij = (gij > gthresh).astype(float)\n",
    "#                 print('gij after thresh', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "                gr = cv2.resize(gij, (gsize,gsize), interpolation=interp)\n",
    "#                 print('gr before dilation', gr.shape, gr.min(), gr.mean(), gr.max())\n",
    "                gr = binary_dilation(gr).astype(int)\n",
    "#                 print('gr after dilation', gr.shape, gr.min(), gr.mean(), gr.max())\n",
    "#                 gin = gi[jj]\n",
    "#                 gin = (gin - gin.min())/(gin.max()-gin.min()+1e-6)\n",
    "#                 grn = cv2.resize(gin, (gsize,gsize), interpolation=interp)\n",
    "#                 print('grn stats', grn.shape, grn.min(), grn.mean(), grn.max())\n",
    "#                 gr = (gr > gthresh).astype(bool).astype(int)\n",
    "#                 print('gr mean batch', jj, np.mean(gr))\n",
    "                for kk in np.nonzero(gts[jj]):\n",
    "                    gmask[jj,kk] = gr\n",
    "#                 print(batch, 'y', gts[jj])\n",
    "#                 print(batch, 'gmask mean', np.average(gmask[jj], axis=(1,2)))\n",
    "            \n",
    "            gmask = torch.from_numpy(gmask).float()\n",
    "            \n",
    "            # keep track of sampling proportions\n",
    "            gt = gts.cpu().detach().numpy()\n",
    "            gs = np.sum(gt,axis=0)\n",
    "            if ii==0: gtsum = gs\n",
    "            else: gtsum += gs\n",
    "            ns += bsize\n",
    "\n",
    "            inputs = inputs.type(torch.float).to(device)\n",
    "            gts = gts.to(device)\n",
    "            gmask = gmask.to(device)\n",
    "            \n",
    "            # predictions are heat maps on a probability scale\n",
    "            logits = net(inputs)\n",
    "            \n",
    "#             class_loss = criterion(logits, gts)\n",
    "            \n",
    "#             first = True\n",
    "#             for kk in range(num_classes):\n",
    "#                 lossk = criterion2(seg[:,kk], gmask[:,kk])\n",
    "#                 # print('seg_loss batch', jj, ' class', kk, lossjk.item())\n",
    "#                 if first: \n",
    "#                     seg_loss = lossk\n",
    "#                     first = False\n",
    "#                 else: seg_loss = seg_loss + lossk\n",
    "#             seg_loss = seg_loss / num_classes\n",
    "\n",
    "             \n",
    "            # print('class_loss', class_loss.item())\n",
    "            # print('seg_loss', seg_loss.item())\n",
    "#             loss = class_loss + 0.5 * seg_loss\n",
    "\n",
    "            loss = criterion(logits, gmask)\n",
    "#             print(ii, loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # adamw\n",
    "            for group in optimizer.param_groups:\n",
    "                for param in group['params']:\n",
    "                    param.data = param.data.add(-p['wd'] * group['lr'], param.data)\n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())                        \n",
    "            running_loss_tr += loss.item()\n",
    "\n",
    "        \n",
    "        print('epoch ' + str(epoch) + ' training class proportions:')\n",
    "        print(gtsum/ns)\n",
    "        \n",
    "        # validation\n",
    "        net.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            val_loss = []\n",
    "            val_predictions = []\n",
    "            val_targets = []\n",
    "        \n",
    "            for ii, sample_batched in enumerate(valloader):\n",
    "\n",
    "                # inputs, gts = sample_batched['image'], sample_batched['gt']\n",
    "                inputs, gts = sample_batched[0], sample_batched[1]\n",
    "\n",
    "                # use thresholded green channel as ground truth mask for current classes\n",
    "                gi = inputs.numpy()[:,1].copy()\n",
    "                bsize = gi.shape[0]\n",
    "                gmask = np.zeros((bsize, num_classes, gsize, gsize)).astype(float)\n",
    "                for jj in range(bsize):\n",
    "                    gr = cv2.resize(gi[jj], (gsize,gsize), interpolation=interp)\n",
    "                    # print('gr shape', gr.shape)\n",
    "                    # gr = (gr > gthresh).astype(bool).astype(int)\n",
    "                    # print('gr mean batch', jj, np.mean(gr))\n",
    "                    for kk in np.nonzero(gts[jj]):\n",
    "                        gmask[jj,kk] = gr\n",
    "\n",
    "                gmask = torch.from_numpy(gmask).float()\n",
    "                \n",
    "                # tta horizontal flip\n",
    "                inputs2 = inputs.numpy()[:,:,:,::-1].copy()\n",
    "                inputs2 = torch.from_numpy(inputs2)\n",
    "\n",
    "                inputs = inputs.type(torch.float).to(device)\n",
    "                inputs2 = inputs2.type(torch.float).to(device)\n",
    "\n",
    "                # predictions are on a logit scale\n",
    "                logits = net(inputs)\n",
    "                logits2 = net(inputs2)\n",
    "                logits2 = logits2.cpu().detach().numpy()[:,:,:,::-1].copy()\n",
    "                logits2 = torch.from_numpy(logits2).to(device)\n",
    "                logits = (logits + logits2)/2.0\n",
    "                \n",
    "                loss = criterion(logits, gmask.to(device))\n",
    "\n",
    "                running_loss_ts += loss.item()\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                # save results to compute F1 on validation set\n",
    "                preds = logits.cpu().detach().numpy()\n",
    "                gt = gts.cpu().detach().numpy()\n",
    "\n",
    "                val_predictions.append(preds)\n",
    "                val_targets.append(gt)\n",
    "\n",
    "            vps = np.vstack(val_predictions)\n",
    "            vts = np.vstack(val_targets)\n",
    "            \n",
    "            # competition metric\n",
    "            # use percentile to as single prediction for f1\n",
    "            vpsp = np.percentile(vps, gpct, axis=(2,3))\n",
    "            thresholds = np.linspace(-5, 5, 101)\n",
    "            scores = np.array([f1_score(vts, np.int32(vpsp > t),\n",
    "                                    average='macro') for t in thresholds])\n",
    "            threshold_best_index = np.argmax(scores)\n",
    "            vf1 = scores[threshold_best_index]\n",
    "            tbest = thresholds[threshold_best_index]\n",
    "            # vf1 = f1_score(vts,(vps > 0).astype(int), average='macro')\n",
    "\n",
    "            if vf1 > best_val:\n",
    "                star = '*'\n",
    "                best_val = vf1\n",
    "                torch.save(net.state_dict(), bname)\n",
    "                bad_epochs = 0\n",
    "            else:\n",
    "                star = ' '\n",
    "                bad_epochs += 1\n",
    "                \n",
    "            # print progress\n",
    "            # running_loss_ts = running_loss_ts / num_img_ts\n",
    "\n",
    "            tl = np.mean(train_loss)\n",
    "            vl = np.mean(val_loss)\n",
    "\n",
    "            stop_time = timeit.default_timer()\n",
    "            diff_time = stop_time - start_time\n",
    "            total_time += diff_time/60.\n",
    "            start_time = timeit.default_timer()\n",
    "\n",
    "            print('epoch %d  train %6.4f  val %6.4f  delta %6.4f  f1 %6.4f%s  thresh %3.1f  time %2.0f%s\\n' % \\\n",
    "                  (epoch, tl, vl, vl-tl, vf1, star, tbest, diff_time, 's'))\n",
    "            writer.add_scalar('loss', tl, epoch)\n",
    "            writer.add_scalar('val_loss', vl, epoch)\n",
    "            writer.add_scalar('delta', vl-tl, epoch)\n",
    "            writer.add_scalar('val_f1', vf1, epoch)\n",
    "            writer.add_scalar('thresh', tbest, epoch)\n",
    "            writer.add_scalar('time', diff_time, epoch)\n",
    "            # print('Running Loss: %f\\n' % running_loss_ts)\n",
    "            # print('Mean Loss: %f\\n' % np.mean(val_loss))\n",
    "            running_loss_tr = 0\n",
    "            running_loss_ts = 0\n",
    "\n",
    "            history['epoch'].append(epoch)\n",
    "            history['train'].append(tl)\n",
    "            history['val'].append(vl)\n",
    "            history['f1'].append(vf1)\n",
    "            history['time'].append(diff_time)\n",
    "\n",
    "            if bad_epochs > p['patience']:\n",
    "                print('early stopping, best validation loss %6.4f, total time %4.1f minutes \\n' % \\\n",
    "                      (best_val, total_time))\n",
    "                break\n",
    "            \n",
    "    writer.close()\n",
    "\n",
    "    # plot history\n",
    "    fig, (ax_loss) = plt.subplots(1, 1, figsize=(8,4))\n",
    "    ax_loss.plot(history['epoch'], history['train'], label=\"Train loss\")\n",
    "    ax_loss.plot(history['epoch'], history['val'], label=\"Validation loss\")\n",
    "    plt.show()\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "best = torch.load(bname, map_location='cpu')\n",
    "# print(best.keys())\n",
    "net.load_state_dict(best)\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # predict validation set\n",
    "    val_logits = []\n",
    "    val_y = []\n",
    "    # for image, mask in tqdm.tqdm(data.DataLoader(dataset_val, batch_size = 30)):\n",
    "    batch = 0\n",
    "    for image, y in valloader:\n",
    "        # test-time augmentation with horizontal flipping\n",
    "        image2 = image.numpy()[:,:,:,::-1].copy()\n",
    "        image2 = torch.from_numpy(image2)\n",
    "        image = image.type(torch.float).to(device)\n",
    "        image2 = image2.type(torch.float).to(device)\n",
    "        logits = net(image)\n",
    "        logits = logits.cpu().detach().numpy()\n",
    "        logits2 = net(image2)\n",
    "        logits2 = logits2.cpu().detach().numpy()\n",
    "        logits2 = logits2[:,:,:,::-1]\n",
    "        logits = (logits + logits2)/2.0\n",
    "        val_logits.append(logits)\n",
    "\n",
    "        y = y.cpu().detach().numpy()\n",
    "        val_y.append(y)\n",
    "\n",
    "        batch += 1\n",
    "\n",
    "    vls = np.vstack(val_logits)\n",
    "    vys = np.vstack(val_y)\n",
    "\n",
    "    print(vls.shape, vys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits.shape,logits.min(),logits.mean(),logits.max())\n",
    "print(logits2.shape,logits2.min(),logits2.mean(),logits2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 15\n",
    "vpc = np.array([np.clip(logits.flatten(),0.,clip), np.clip(logits2.flatten(),0.,clip)])\n",
    "\n",
    "# tpsf = np.hstack([c.reshape((-1,1)) for c in tps])\n",
    "print(vpc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(vpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out-of-fold predictions\n",
    "oof_ids = file_list_val\n",
    "poof = vls.copy()\n",
    "yoof = vys.copy()\n",
    "\n",
    "oof = [oof_ids, poof, yoof]\n",
    "fname = 'oof/'+mname+'_'+str(fold)+'.pkl'\n",
    "pickle.dump(oof,open(fname,'wb'))\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for best threshold\n",
    "# note predictions and thresholds are on logit scale\n",
    "vlsp = np.percentile(vls, gpct, axis=(2,3))\n",
    "# vlsp = np.average(vls, axis=(2,3))\n",
    "\n",
    "thresholds = np.linspace(-5, 10, 151)\n",
    "scores = np.array([f1_score(vys, (vlsp > t).astype(int), average='macro') \\\n",
    "                 for t in thresholds])\n",
    "\n",
    "threshold_best_index = np.argmax(scores)\n",
    "score_best = scores[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "print('')\n",
    "print('f1_best',score_best)\n",
    "print('threshold_best',threshold_best)\n",
    "print('')\n",
    "\n",
    "plt.plot(thresholds, scores)\n",
    "plt.plot(threshold_best, score_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1\")\n",
    "plt.title(\"Threshold vs F1 ({}, {})\".format(threshold_best, score_best))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = vlsp.flatten()\n",
    "print(vf.min(),vf.mean(),vf.max(),vf.shape)\n",
    "sns.distplot(vf)\n",
    "plt.title(\"Distribution of Predictions (Logit Scale) for Fold \" + str(fold+1))\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(vys,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = [confusion_matrix(vys[:,i], (vlsp[:,i] > threshold_best).astype(int)) \\\n",
    "       for i in range(vys.shape[1])]\n",
    "fm = [f1_score(vys[:,i], (vlsp[:,i] > threshold_best).astype(int)) \\\n",
    "       for i in range(vys.shape[1])]\n",
    "for i in range(vys.shape[1]):\n",
    "    print(LABEL_MAP[i])\n",
    "    print(cm[i], '%4.2f' % fm[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fm1 = [f for f in fm if f > 0]\n",
    "# print(len(fm1))\n",
    "# print(np.mean(fm1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1b = np.array([f1_score(y, (l > threshold_best).astype(int)) \\\n",
    "                 for y,l in zip(vys,vlsp)])\n",
    "print(f1b.min(),f1b.mean(),f1b.max())\n",
    "sns.distplot(f1b)\n",
    "plt.title(\"Distribution of Sample F1 Scores for Fold \" + str(fold))\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation images with scores\n",
    "# sort from worst to best\n",
    "order = f1b.argsort()\n",
    "max_images = 90\n",
    "# max_images = len(file_list_val)\n",
    "start = 0\n",
    "# start = 200\n",
    "grid_width = 10\n",
    "grid_height = int(max_images / grid_width)\n",
    "# print(max_images,grid_height,grid_width)\n",
    "\n",
    "file_list_val_reordered = [file_list_val[order[i]] for i,f in enumerate(file_list_val)]\n",
    "\n",
    "for i, idx in enumerate([file_list_val_reordered[i] for i in range(start,(start+max_images))]):\n",
    "    imod = i % 30\n",
    "    if imod == 0:\n",
    "        fig, axs = plt.subplots(3, 10, figsize=(30, 10))\n",
    "    img, y = db_val[order[i]]\n",
    "\n",
    "    img = img.data.numpy()[1]\n",
    "    img = img[y_min_pad:(image_size - y_max_pad), x_min_pad:(image_size - x_max_pad)]\n",
    "\n",
    "    true = np.nonzero(vys[order][start+i])\n",
    "    true_str = ' '.join(map(str, true))\n",
    "    pred = np.nonzero((vlsp[order][start+i] > threshold_best).astype(int))\n",
    "    pred_str = ' '.join(map(str, pred))\n",
    "    ax = axs[int(imod / grid_width), imod % grid_width]\n",
    "    ax.imshow(img, cmap='Greens')\n",
    "    ax.set_title(str(i) + '   ' + idx[:13] + '\\n' + true_str + '  ' + pred_str)\n",
    "    # ax.set_xlabel(str(round(ioub[i], 3)))\n",
    "    ax.set_xlabel('%4.2f' % (f1b[order][start+i]))\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    if imod == 29:\n",
    "        # plt.suptitle(\"Green: salt, Red: prediction. Top-left: coverage class, Top-right: salt coverage, Bottom-left: depth, Bottom-right: IOU\")\n",
    "        plt.show()\n",
    "        plt.gcf().clear()\n",
    "        gc.collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ss.head())\n",
    "print(ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_test = MultiBandMultiLabelDataset(ss, train_mode=False,\n",
    "                                    base_path=PATH_TO_TEST,\n",
    "                                    image_transform=composed_transforms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(db_test, collate_fn=db_test.collate_func,\n",
    "                       batch_size=p['testBatch'], shuffle=False,\n",
    "                      num_workers=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 20\n",
    "with torch.no_grad():\n",
    "    print('predicting test set for bagging')\n",
    "    tp = {}\n",
    "    for i in range(8): tp[i] = []\n",
    "    \n",
    "    # 8-way TTA\n",
    "    # for image in tqdm.tqdm(data.DataLoader(test_dataset, batch_size = 30)):\n",
    "    for image in testloader:\n",
    "        i = 0\n",
    "        image1 = image[0].numpy().copy()\n",
    "        # move channels last for augmentation\n",
    "        image1 = np.transpose(image1, (0, 2, 3, 1))\n",
    "       \n",
    "        image = image[0].type(torch.float).to(device)\n",
    "        logits = net(image)\n",
    "        logits = logits.cpu().detach().numpy()\n",
    "        logits = np.clip(logits,-clip,clip)\n",
    "        tp[i].append(logits)\n",
    "        i += 1\n",
    "       \n",
    "        for degrees in [90, 180, 270]:\n",
    "            IAA = iaa.Affine(rotate=degrees)\n",
    "            image2 = np.array([IAA.augment_image(imi) for imi in image1])\n",
    "            # move channels first for pytorch\n",
    "            image2 = np.transpose(image2, (0, 3, 1, 2))\n",
    "            image2 = torch.from_numpy(image2)\n",
    "            image2 = image2.type(torch.float).to(device)\n",
    "            logits2 = net(image2)\n",
    "            logits2 = logits2.cpu().detach().numpy()\n",
    "            logits2 = np.clip(logits2,-clip,clip)\n",
    "            IAA = iaa.Affine(rotate=-degrees)\n",
    "            logits2 = np.transpose(logits2, (0, 2, 3, 1))\n",
    "            logits2 = np.array([IAA.augment_image(imi) for imi in logits2])\n",
    "            logits2 = np.transpose(logits2, (0, 3, 1, 2))\n",
    "            tp[i].append(logits2)\n",
    "            i += 1\n",
    "        \n",
    "        # horizontally flip image1\n",
    "        IAA = iaa.Fliplr(1.0)\n",
    "        image1 = np.array([IAA.augment_image(imi) for imi in image1])\n",
    "        image2 = np.transpose(image1, (0, 3, 1, 2))\n",
    "        image2 = torch.from_numpy(image2)\n",
    "        image2 = image2.type(torch.float).to(device)\n",
    "        logits2 = net(image2)\n",
    "        logits2 = logits2.cpu().detach().numpy()\n",
    "        logits2 = np.clip(logits2,-clip,clip)\n",
    "        logits2 = np.transpose(logits2, (0, 2, 3, 1))\n",
    "        logits2 = np.array([IAA.augment_image(imi) for imi in logits2])\n",
    "        logits2 = np.transpose(logits2, (0, 3, 1, 2))\n",
    "        tp[i].append(logits2)\n",
    "        i += 1\n",
    "        \n",
    "        # rotations again on flipped image\n",
    "        for degrees in [90, 180, 270]:\n",
    "            IAA = iaa.Affine(rotate=degrees)\n",
    "            image2 = np.array([IAA.augment_image(imi) for imi in image1])\n",
    "            image2 = np.transpose(image2, (0, 3, 1, 2))\n",
    "            image2 = torch.from_numpy(image2)\n",
    "            image2 = image2.type(torch.float).to(device)\n",
    "            logits2 = net(image2)\n",
    "            logits2 = logits2.cpu().detach().numpy()\n",
    "            logits2 = np.clip(logits2,-clip,clip)\n",
    "            IAA = iaa.Affine(rotate=-degrees)\n",
    "            logits2 = np.transpose(logits2, (0, 2, 3, 1))\n",
    "            logits2 = np.array([IAA.augment_image(imi) for imi in logits2])\n",
    "            logits2 = np.transpose(logits2, (0, 3, 1, 2))\n",
    "            tp[i].append(logits2)\n",
    "            i += 1\n",
    "         \n",
    "    tps = np.array([np.vstack(tp[i]) for i in range(8)])\n",
    "    print(tps.shape)\n",
    "\n",
    "tpsf = np.hstack([c.reshape((-1,1)) for c in tps])\n",
    "print(tpsf.shape)\n",
    "\n",
    "np.set_printoptions(precision=3,linewidth=100)\n",
    "print(np.corrcoef(tpsf, rowvar=False))\n",
    "\n",
    "ptest = np.median(tps,axis=0)\n",
    "ptesta = np.amax(tps,axis=0)\n",
    "print(ptest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some test images\n",
    "nshow = 50\n",
    "start = np.random.randint(len(test_file_list)-nshow)\n",
    "stop = start + nshow\n",
    "grid_width = 10\n",
    "grid_height = int(max_images / grid_width)\n",
    "# print(max_images,grid_height,grid_width)\n",
    "ni = 10\n",
    "for j in range(int(start/10),int(stop/10)):\n",
    "    jj = j*10\n",
    "    fig, axs = plt.subplots(3, ni, figsize=(20,8))\n",
    "    for i in range(ni):\n",
    "        img = db_test[jj+i]\n",
    "        img = img[0].data.numpy()\n",
    "        img = img[:,y_min_pad:(image_size - y_max_pad),\n",
    "                    x_min_pad:(image_size - x_max_pad)]\n",
    "        # img = cv2.resize(img,(ori_size,ori_size),interpolation=interp)\n",
    "        pred = np.nonzero((ptest[jj+i] > threshold_best).astype(int))\n",
    "        # pred_str = list(pred)\n",
    "        # pred_str = np.char.mod('%d', pred)\n",
    "        # pred_str = \" \".join(pred_str)\n",
    "        pred_str = ' '.join(map(str, pred))\n",
    "        axs[0][i].imshow(img[0], cmap=\"Reds\")\n",
    "        axs[1][i].imshow(img[1], cmap=\"Greens\")\n",
    "        axs[2][i].imshow(img[2], cmap=\"Blues\")\n",
    "#         axs[3][i].imshow(img[3], cmap=\"Oranges\")\n",
    "        axs[0][i].set_title(pred_str)\n",
    "    # fig.suptitle(\"Top row: original, bottom row: green channel\")\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "\n",
    "#     # clean up to save on memory accumulation across folds\n",
    "#     del net\n",
    "#     del inputs, gts\n",
    "#     del image, image2\n",
    "#     del writer, scheduler, optimizer\n",
    "#     del y_pred, y_pred2\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = [test_file_list, ptest, ptesta]\n",
    "fname = 'sub/'+mname+'_'+str(fold)+'_mm.pkl'\n",
    "pickle.dump(sub,open(fname,'wb'))\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
