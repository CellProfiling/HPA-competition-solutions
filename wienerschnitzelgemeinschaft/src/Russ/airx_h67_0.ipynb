{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = 'airx_h67'\n",
    "seed = 723\n",
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "nfold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights from this model\n",
    "mname0 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import timeit\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import random\n",
    "import PIL\n",
    "import pathlib\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau, StepLR\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torchvision\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from skimage.exposure import histogram, equalize_hist, equalize_adapthist\n",
    "from skimage.morphology import binary_dilation\n",
    "\n",
    "import pretrainedmodels\n",
    "from xception import xception\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from scipy.special import logit\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from sklearn.metrics import jaccard_similarity_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import multiprocessing\n",
    "import threading\n",
    "\n",
    "from dataloaders import utils\n",
    "from dataloaders import custom_transforms as tr\n",
    "\n",
    "# from losses import CombinedLoss, BCELoss2d\n",
    "from losses import FocalLoss, ThreeWayLoss, L1_LossW, Smooth_L1_LossW\n",
    "import lovasz_losses as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7114b9f3da03d4688ecfdecd7c7008a0be0c8004",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 1024 1024 1024\n"
     ]
    }
   ],
   "source": [
    "ori_size = 1024\n",
    "up_size = 1024\n",
    "image_size = 1024\n",
    "final_size = 1024\n",
    "\n",
    "interp = cv2.INTER_AREA\n",
    "# methods=[(\"area\", cv2.INTER_AREA), \n",
    "#          (\"nearest\", cv2.INTER_NEAREST), \n",
    "#          (\"linear\", cv2.INTER_LINEAR), \n",
    "#          (\"cubic\", cv2.INTER_CUBIC), \n",
    "#          (\"lanczos4\", cv2.INTER_LANCZOS4)]\n",
    "\n",
    "y_pad = image_size - up_size\n",
    "y_min_pad = int(y_pad / 2)\n",
    "y_max_pad = y_pad - y_min_pad\n",
    "\n",
    "x_pad = image_size - up_size\n",
    "x_min_pad = int(x_pad / 2)\n",
    "x_max_pad = x_pad - x_min_pad\n",
    "\n",
    "print(ori_size, up_size, image_size, final_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "\n",
    "PATH_TO_TRAIN = PATH + 'train_1024/'\n",
    "PATH_TO_TEST = PATH + 'test_1024/'\n",
    "PATH_TO_EXTERNAL = PATH + 'external_data/'\n",
    "PATH_TO_EXTERNAL2 = './external_data2/'\n",
    "PATH_TO_EXTERNAL3 = './external_data3/'\n",
    "PATH_TO_TARGET = PATH + 'train.csv'\n",
    "PATH_TO_TARGETX = PATH + 'subcellular_location.tsv'\n",
    "PATH_TO_TARGETXX = './HPAv18Y.csv'\n",
    "PATH_TO_SUB = PATH + 'sample_submission.csv'\n",
    "PATH_TO_PSEUDO = PATH + 'sub/b650.csv'\n",
    "\n",
    "clusters = pd.read_csv('cluster2emb.csv')\n",
    "folds = dict(zip(clusters.Id,clusters.fold))\n",
    "\n",
    "LABEL_MAP = {\n",
    "0: \"Nucleoplasm\" ,\n",
    "1: \"Nuclear membrane\"   ,\n",
    "2: \"Nucleoli\"   ,\n",
    "3: \"Nucleoli fibrillar center\",   \n",
    "4: \"Nuclear speckles\"   ,\n",
    "5: \"Nuclear bodies\"   ,\n",
    "6: \"Endoplasmic reticulum\"   ,\n",
    "7: \"Golgi apparatus\"  ,\n",
    "8: \"Peroxisomes\"   ,\n",
    "9:  \"Endosomes\"   ,\n",
    "10: \"Lysosomes\"   ,\n",
    "11: \"Intermediate filaments\"  , \n",
    "12: \"Actin filaments\"   ,\n",
    "13: \"Focal adhesion sites\"  ,\n",
    "14: \"Microtubules\"   ,\n",
    "15: \"Microtubule ends\"   ,\n",
    "16: \"Cytokinetic bridge\"   ,\n",
    "17: \"Mitotic spindle\"  ,\n",
    "18: \"Microtubule organizing center\",  \n",
    "19: \"Centrosome\",\n",
    "20: \"Lipid droplets\"   ,\n",
    "21: \"Plasma membrane\"  ,\n",
    "22: \"Cell junctions\"   ,\n",
    "23: \"Mitochondria\"   ,\n",
    "24: \"Aggresome\"   ,\n",
    "25: \"Cytosol\" ,\n",
    "26: \"Cytoplasmic bodies\",\n",
    "27: \"Rods & rings\"}\n",
    "\n",
    "LOC_MAP = {}\n",
    "for k in LABEL_MAP.keys(): LOC_MAP[LABEL_MAP[k]] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'imagenet': {'url': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth', 'input_space': 'RGB', 'input_size': [3, 224, 224], 'input_range': [0, 1], 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'num_classes': 1000}}\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.pretrained_settings['resnet34'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "95e82b2a7155377310f1d743dd8b077f99cba657",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Target\n",
      "Id                                           \n",
      "00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
      "000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
      "000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
      "000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
      "001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18\n",
      "(31072, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH_TO_TARGET)\n",
    "df.set_index('Id',inplace=True)\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # external data\n",
    "# # https://www.proteinatlas.org/download/subcellular_location.tsv.zip\n",
    "# dg = pd.read_csv(PATH_TO_TARGETX, sep=\"\\t\",index_col = None)\n",
    "# dg.set_index('Gene',inplace=True)\n",
    "# print(dg.head())\n",
    "# print(dg.shape)\n",
    "\n",
    "# file_list_x = [f for f in listdir(PATH_TO_EXTERNAL) if isfile(join(PATH_TO_EXTERNAL,\n",
    "#                                                                    f))]\n",
    "# print(file_list_x[:15],len(file_list_x))\n",
    "\n",
    "# fid = [f[:-4] for f in file_list_x]\n",
    "# gene = [i[:15] for i in fid]\n",
    "# rel = [dg.loc[g]['Reliability'] for g in gene]\n",
    "\n",
    "# s0 = [str(dg.loc[g]['Enhanced']).split(';') for g in gene]\n",
    "# t0 = [' '.join([str(LOC_MAP[j]) for j in i if j in LOC_MAP]).strip() for i in s0]\n",
    "\n",
    "# s1 = [str(dg.loc[g]['Supported']).split(';') for g in gene]\n",
    "# t1 = [' '.join([str(LOC_MAP[j]) for j in i if j in LOC_MAP]).strip() for i in s1]\n",
    "\n",
    "# s2 = [str(dg.loc[g]['Approved']).split(';') for g in gene]\n",
    "# t2 = [' '.join([str(LOC_MAP[j]) for j in i if j in LOC_MAP]).strip() for i in s2]\n",
    "\n",
    "# s3 = [str(dg.loc[g]['Uncertain']).split(';') for g in gene]\n",
    "# t3 = [' '.join([str(LOC_MAP[j]) for j in i if j in LOC_MAP]).strip() for i in s3]\n",
    "\n",
    "# t = [[y for y in z if len(y) > 0] for z in zip(t0,t1,t2,t3)]\n",
    "# targ = [' '.join(y).strip() for y in t]\n",
    "\n",
    "# print(s0[:20],t0[:20],s1[:20],t1[:20],s2[:20],t2[:20],s3[:20],t3[:20])\n",
    "\n",
    "# dfx = pd.DataFrame({'Id':fid,'Gene':gene,'Reliability':rel,'Target':targ})\n",
    "\n",
    "# print(dfx.shape)\n",
    "\n",
    "# dfx = dfx[dfx['Target'] != '']\n",
    "\n",
    "# print(dfx.head())\n",
    "# print(dfx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Target  GotYellow\n",
      "Id                                             \n",
      "ENSG00000000003_4109_24_H11_1     25          1\n",
      "ENSG00000000003_4109_24_H11_2     25          1\n",
      "ENSG00000000003_4109_23_H11_1     25          1\n",
      "ENSG00000000003_4109_23_H11_2     25          1\n",
      "ENSG00000000003_4109_25_H11_1     25          1\n",
      "(77444, 2)\n"
     ]
    }
   ],
   "source": [
    "# from Tomomi\n",
    "dfxx = pd.read_csv(PATH_TO_TARGETXX, index_col = None)\n",
    "dfxx.set_index('Id',inplace=True)\n",
    "dfxx = dfxx[dfxx.GotYellow==1]\n",
    "print(dfxx.head())\n",
    "print(dfxx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_xx = list(dfxx.index.values)\n",
    "\n",
    "# drop Ids with incomplete data\n",
    "# file_list_xx0 = list(dfxx.index.values)\n",
    "# file_list_xx = []\n",
    "# bands = ['_red.jpg','_green.jpg','_blue.jpg']\n",
    "# for f in file_list_xx0:\n",
    "#     ok = True\n",
    "#     for b in bands:\n",
    "#         if not os.path.exists(PATH_TO_EXTERNAL2+f+b): ok = False\n",
    "#     if ok: file_list_xx.append(f)\n",
    "        \n",
    "# print(len(file_list_xx0),len(file_list_xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "95e82b2a7155377310f1d743dd8b077f99cba657",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Predicted\n",
      "Id                                             \n",
      "00008af0-bad0-11e8-b2b8-ac1f6b6435d0          0\n",
      "0000a892-bacf-11e8-b2b8-ac1f6b6435d0          0\n",
      "0006faa6-bac7-11e8-b2b7-ac1f6b6435d0          0\n",
      "0008baca-bad7-11e8-b2b9-ac1f6b6435d0          0\n",
      "000cce7e-bad4-11e8-b2b8-ac1f6b6435d0          0\n",
      "(11702, 1)\n"
     ]
    }
   ],
   "source": [
    "file_list = list(df.index.values)\n",
    "\n",
    "ss = pd.read_csv(PATH_TO_SUB)\n",
    "ss.set_index('Id',inplace=True)\n",
    "print(ss.head())\n",
    "print(ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "95e82b2a7155377310f1d743dd8b077f99cba657",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Target\n",
      "Id                                          \n",
      "00008af0-bad0-11e8-b2b8-ac1f6b6435d0       2\n",
      "0000a892-bacf-11e8-b2b8-ac1f6b6435d0       5\n",
      "0006faa6-bac7-11e8-b2b7-ac1f6b6435d0  0 5 25\n",
      "0008baca-bad7-11e8-b2b9-ac1f6b6435d0       0\n",
      "000cce7e-bad4-11e8-b2b8-ac1f6b6435d0     NaN\n",
      "(11702, 1)\n"
     ]
    }
   ],
   "source": [
    "ssp = pd.read_csv(PATH_TO_PSEUDO)\n",
    "ssp.set_index('Id',inplace=True)\n",
    "ssp.columns = ['Target']\n",
    "print(ssp.head())\n",
    "print(ssp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "95e82b2a7155377310f1d743dd8b077f99cba657",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', '000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', '000a9596-bbc4-11e8-b2bc-ac1f6b6435d0'] ./train_1024/ 31072\n",
      "['00008af0-bad0-11e8-b2b8-ac1f6b6435d0', '0000a892-bacf-11e8-b2b8-ac1f6b6435d0', '0006faa6-bac7-11e8-b2b7-ac1f6b6435d0'] ./test_1024/ 11702\n"
     ]
    }
   ],
   "source": [
    "test_file_list = list(ss.index.values)\n",
    "print(file_list[:3], PATH_TO_TRAIN, len(file_list))\n",
    "print(test_file_list[:3], PATH_TO_TEST, len(test_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_histogram_equalization(image, number_bins=256):\n",
    "    # from http://www.janeriksolem.net/2009/06/histogram-equalization-with-python-and.html\n",
    "\n",
    "    # get image histogram\n",
    "    image_histogram, bins = np.histogram(image.flatten(), number_bins, density=True)\n",
    "    cdf = image_histogram.cumsum() # cumulative distribution function\n",
    "    cdf = 255 * cdf / cdf[-1] # normalize\n",
    "\n",
    "    # use linear interpolation of cdf to find new pixel values\n",
    "    image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n",
    "\n",
    "    # return image_equalized.reshape(image.shape), cdf\n",
    "    return image_equalized.reshape(image.shape)\n",
    "\n",
    "def equalize(arr):\n",
    "    arr = arr.astype('float')\n",
    "    # usually do not touch the alpha channel\n",
    "    # but here we do since it is yellow\n",
    "    for i in range(arr.shape[-1]):\n",
    "        # arr[...,i] = 255 * equalize_hist(arr[...,i])\n",
    "        arr[...,i] = image_histogram_equalization(arr[...,i])                                  \n",
    "    return arr\n",
    "\n",
    "def normalize(arr, q=0.01):\n",
    "    arr = arr.astype('float')\n",
    "    # usually do not touch the alpha channel\n",
    "    # but here we do since it is yellow\n",
    "    # print('arr before',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    for i in range(arr.shape[-1]):\n",
    "        # arr[...,i] = 255 * equalize_hist(arr[...,i])\n",
    "        ai = arr[...,i]\n",
    "        # print('ai ' + str(i) + ' before',i,ai.shape,ai.min(),ai.mean(),ai.max())\n",
    "        qlow = np.percentile(ai,100*q)\n",
    "        qhigh = np.percentile(ai,100*(1.0-q))\n",
    "        if qlow == qhigh:\n",
    "            arr[...,i] = 0.\n",
    "        else:\n",
    "            arr[...,i] = 255.*(np.clip(ai,qlow,qhigh) - qlow)/(qhigh - qlow)                              \n",
    "        # print('ai ' + str(i) + ' after',i,ai.shape,ai.min(),ai.mean(),ai.max())\n",
    "    # print('arr after',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    return arr\n",
    "\n",
    "def standardize(arr):\n",
    "    arr = arr.astype('float')\n",
    "    # usually do not touch the alpha channel\n",
    "    # but here we do since it is yellow\n",
    "    # print('arr before',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    for i in range(arr.shape[-1]):\n",
    "        # arr[...,i] = 255 * equalize_hist(arr[...,i])\n",
    "        ai = (arr[...,i] - arr.mean())/(arr.std() + 1e-6)\n",
    "        # print('ai ' + str(i) + ' after',i,ai.shape,ai.min(),ai.mean(),ai.max())\n",
    "    # print('arr after',arr.shape,arr.min(),arr.mean(),arr.max())\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "class MultiBandMultiLabelDataset(Dataset):\n",
    "    \n",
    "#     BANDS_NAMES = ['_red.png','_green.png','_blue.png','_yellow.png']\n",
    "#     BANDS_NAMES = ['_red','_green','_blue','_yellow']\n",
    "    BANDS_NAMES = ['_red','_green','_blue']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_df)\n",
    "    \n",
    "    def __init__(self, images_df, \n",
    "                 base_path, \n",
    "                 image_transform=None, \n",
    "                 augmentator=None,\n",
    "                 train_mode=True,\n",
    "                 external=0\n",
    "                ):\n",
    "        if not isinstance(base_path, pathlib.Path):\n",
    "            base_path = pathlib.Path(base_path)\n",
    "            \n",
    "        self.images_df = images_df.reset_index()\n",
    "        self.image_transform = image_transform\n",
    "        self.augmentator = augmentator\n",
    "        self.images_df.Id = self.images_df.Id.apply(lambda x: base_path / x)\n",
    "        self.mlb = MultiLabelBinarizer(classes=list(LABEL_MAP.keys()))\n",
    "        self.train_mode = train_mode\n",
    "        self.external = external\n",
    "        if self.external == 2: self.suffix = '.jpg'\n",
    "        else: self.suffix = '.png'\n",
    "        self.cache = {}\n",
    "                                 \n",
    "    def __getitem__(self, index):\n",
    "        # print('index class',index.__class__)\n",
    "        if isinstance(index, torch.Tensor): index = index.item()\n",
    "            \n",
    "#         if index in self.cache: \n",
    "#             X, y = self.cache[index]\n",
    "#         else:\n",
    "#             y = None\n",
    "#             X = self._load_multiband_image(index)\n",
    "#             if self.train_mode:\n",
    "#                 y = self._load_multilabel_target(index)\n",
    "#             self.cache[index] = (X,y)\n",
    "            \n",
    "        y = None\n",
    "        X = self._load_multiband_image(index)\n",
    "        if self.train_mode:\n",
    "            y = self._load_multilabel_target(index)\n",
    "        \n",
    "        \n",
    "        # augmentator can be for instance imgaug augmentation object\n",
    "        if self.augmentator is not None:\n",
    "#             print('getitem before aug',X.shape,np.min(X),np.mean(X),np.max(X))\n",
    "#             X = self.augmentator(np.array(X))\n",
    "            X = self.augmentator(image=X)['image']\n",
    "#             print('getitem after aug',X.shape,np.min(X),np.mean(X),np.max(X))\n",
    "           \n",
    "        if self.image_transform is not None:\n",
    "            X = self.image_transform(X)\n",
    "        \n",
    "        return X, y \n",
    "        \n",
    "    def _load_multiband_image(self, index):\n",
    "        row = self.images_df.iloc[index]\n",
    "        \n",
    "        if self.external in [1,3]:\n",
    "            p = str(row.Id.absolute()) + self.suffix\n",
    "            band3image = PIL.Image.open(p)\n",
    "        elif self.external in [4,5]:\n",
    "            p = str(row.Id.absolute()) + self.suffix\n",
    "            band4image = PIL.Image.open(p)\n",
    "        else:\n",
    "            image_bands = []\n",
    "            for i,band_name in enumerate(self.BANDS_NAMES):\n",
    "                p = str(row.Id.absolute()) + band_name + self.suffix\n",
    "                pil_channel = PIL.Image.open(p)\n",
    "                if self.external == 2: \n",
    "                    pa = np.array(pil_channel)[...,i]  \n",
    "#                     pa = np.array(pil_channel)\n",
    "#                     print(i,band_name,pil_channel.mode,pa.shape,pa.min(),pa.mean(),pa.max())\n",
    "                    if pa.max() > 0:\n",
    "                        pil_channel = PIL.Image.fromarray(pa.astype('uint8'),'L')\n",
    "                    pil_channel = pil_channel.convert(\"L\")\n",
    "                image_bands.append(pil_channel)\n",
    "\n",
    "            # pretend its a RBGA image to support 4 channels\n",
    "#             band4image = PIL.Image.merge('RGBA', bands=image_bands)\n",
    "            band3image = PIL.Image.merge('RGB', bands=image_bands)\n",
    "    \n",
    "#         band4image = band4image.resize((image_size,image_size), PIL.Image.ANTIALIAS)\n",
    "        band3image = band3image.resize((image_size,image_size), PIL.Image.ANTIALIAS)\n",
    "\n",
    "#         # normalize each channel     \n",
    "#         arr = np.array(band4image)\n",
    "# #         arr = np.array(band3image)\n",
    "    \n",
    "# #         # average red and yellow channels, orange\n",
    "# #         arr[...,0] = (arr[...,0] + arr[...,3])/2.0\n",
    "# #         arr = arr[...,:3]\n",
    "        \n",
    "#         # arr = np.array(band3image)\n",
    "#         # print('arr shape',arr.shape)\n",
    "#         # if index==0: print(index,'hist before',histogram(arr))\n",
    "        \n",
    "#         arr = normalize(arr)\n",
    "# #         arr = standardize(arr)\n",
    "# #         arr = equalize(arr)\n",
    "        \n",
    "# #         # average red and yellow channels, orange\n",
    "# #         arr[...,0] = (arr[...,0] + arr[...,3])/2.0\n",
    "# #         arr = arr[...,:3]\n",
    "                \n",
    "#         # if index==0: print(index,'hist after',histogram(arr))\n",
    "# #         band3image = PIL.Image.fromarray(arr.astype('uint8'),'RGB')\n",
    "#         band4image = PIL.Image.fromarray(arr.astype('uint8'),'RGBA')\n",
    "\n",
    "        # histogram equalize each channel\n",
    "        \n",
    "#         arr = np.array(band4image)\n",
    "#         # print('arr',arr.shape)\n",
    "#         # if index==0: print(index,'hist before',histogram(arr))\n",
    "#         arr = equalize(arr)\n",
    "#         # if index==0: print(index,'hist after',histogram(arr))\n",
    "#         band4image = PIL.Image.fromarray(arr.astype('uint8'),'RGBA')\n",
    "        \n",
    "#         return band4image\n",
    "        return band3image\n",
    "#         return arr\n",
    "\n",
    "#         band3image = PIL.Image.new(\"RGB\", band4image.size, (255, 255, 255))\n",
    "#         band3image.paste(band4image, mask=band4image.split()[3]) \n",
    "#         band3image = band3image.resize((image_size,image_size), PIL.Image.ANTIALIAS)\n",
    "#         return band3image\n",
    "   \n",
    "    \n",
    "    def _load_multilabel_target(self, index):\n",
    "        y = self.images_df.iloc[index].Target.split(' ')\n",
    "#         print(y)\n",
    "        try:\n",
    "            yl = list(map(int, y))\n",
    "        except:\n",
    "            yl = []\n",
    "        return yl\n",
    "    \n",
    "        \n",
    "    def collate_func(self, batch):\n",
    "        labels = None\n",
    "        images = [x[0] for x in batch]\n",
    "        \n",
    "        if self.train_mode:\n",
    "            labels = [x[1] for x in batch]\n",
    "            labels_one_hot  = self.mlb.fit_transform(labels)\n",
    "            labels = torch.FloatTensor(labels_one_hot)\n",
    "            \n",
    "        \n",
    "        # return torch.stack(images)[:,:4,:,:], labels\n",
    "        return torch.stack(images), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imean = (0.08069, 0.05258, 0.05487, 0.08069)\n",
    "istd = (0.13704, 0.10145, 0.15313, 0.13704)\n",
    "\n",
    "train_aug = A.Compose([\n",
    "#                         A.Rotate((0,30),p=0.75),\n",
    "                        A.RandomRotate90(p=1),\n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.ShiftScaleRotate(p=0.9),\n",
    "#                         A.RandomBrightness(0.05),\n",
    "#                         A.RandomContrast(0.05),\n",
    "                        A.Normalize(mean=imean, std=istd,max_pixel_value=255.)\n",
    "                        ])\n",
    "\n",
    "test_aug = A.Compose([\n",
    "                        A.Normalize(mean=imean, std=istd,max_pixel_value=255.)\n",
    "                        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_transforms_train = transforms.Compose([\n",
    "#     transforms.Resize(size=final_size),\n",
    "#     transforms.RandomResizedCrop(size=512,scale=0.5),\n",
    "    transforms.RandomCrop(size=512),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "#     transforms.RandomRotation(degrees=45),\n",
    "    transforms.RandomAffine(degrees=45, translate=(0.1,0.1), shear=10, scale=(0.9,1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imean, std=istd)\n",
    "])\n",
    "\n",
    "composed_transforms_test = transforms.Compose([\n",
    "#     transforms.Resize(size=final_size),\n",
    "    transforms.FiveCrop(512), \n",
    "    transforms.Lambda(lambda crops: torch.stack([ \\\n",
    "        transforms.ToTensor()(crop) for crop in crops])),\n",
    "    transforms.Lambda(lambda crops: torch.stack([ \\\n",
    "        transforms.Normalize(mean=imean, std=istd)(crop) for crop in crops]))\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=imean, std=istd)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# model and main parameter settings #\n",
    "#####################################\n",
    "\n",
    "%run 'airx67u.ipynb'\n",
    "\n",
    "device = \"cuda:\"+str(gpu_id)\n",
    "# device = \"cpu\"\n",
    "\n",
    "p = OrderedDict()  # Parameters to include in report\n",
    "p['trainBatch'] = 16  # Training batch size\n",
    "p['testBatch'] = 16  # Testing batch size\n",
    "\n",
    "nEpochs = 24  # Number of epochs for training\n",
    "resume_epoch = 0  # Default is 0, change if want to resume\n",
    "\n",
    "p['lr'] = 1e-4  # Learning rate\n",
    "p['step_size'] = 5\n",
    "p['gamma'] = 0.5\n",
    "p['wd'] = 1e-4  # Weight decay\n",
    "p['momentum'] = 0.9  # Momentum\n",
    "p['epoch_size'] = 15 # How many epochs to change learning rate\n",
    "p['patience'] = 30 # epochs to wait for early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./airx_h67/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 28\n",
    "gsize = 1\n",
    "gpct = 95.\n",
    "gstd = 0.1\n",
    "gthresh = 0.1\n",
    "eps = 1e-5\n",
    "\n",
    "# save_dir_root = os.path.join(os.path.dirname(os.path.abspath(__file__)))\n",
    "# exp_name = os.path.dirname(os.path.abspath(__file__)).split('/')[-1]\n",
    "\n",
    "save_dir_root = './'\n",
    "\n",
    "# save_dir = os.path.join(save_dir_root, 'run', 'run_' + str(run_id))\n",
    "save_dir = save_dir_root + mname + '/'\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "print(save_dir)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "airx_h67 fold 0\n",
      "**************************************************\n",
      "Number of parameters: 26,620,028\n",
      "Using GPU: 0 \n",
      "Training on 19527 and validating on 11545\n",
      "Sampling weights:\n",
      "[    1.757     18.8667     7.2753    19.1441    12.2503    11.3794    41.3708\n",
      "    12.9318  1502.0769  3254.5    19527.        33.2658    55.4744    74.2471\n",
      "    65.9696  1148.6471    58.1161   157.4758    40.345     22.3933   330.9661\n",
      "     8.4496    42.45      15.7222   144.6444     3.5523   106.7049  2789.5714]\n",
      "Sampling weights external2:\n",
      "[   2.6813   41.1062   10.2847   42.3654   22.8718   22.2349   26.937\n",
      "   11.4919  472.2195  509.5     502.8831   67.0511   49.9961   82.651\n",
      "   44.8171 1843.9048   99.799   322.6833   76.9057   33.4676  270.7832\n",
      "    7.3616   39.2917   10.2169  730.6038    2.5482  195.5657  634.7869]\n",
      "Sampling weights pseudo:\n",
      "[   2.182    22.3748   11.6786   18.0866   15.3974   13.5127   24.74\n",
      "   12.1769  835.8571  557.2381  585.1      23.3573   27.088    65.3743\n",
      "   22.3748 2340.4      37.3866   56.5314   29.7005   16.7171  191.8361\n",
      "    6.7798   33.2443   11.7255   92.873     3.4037   42.3986 1300.2222]\n",
      "Image size: 1024\n",
      "Batch size: 16\n",
      "Batches per epoch: 3255\n",
      "Epochs: 24\n",
      "Loss: BCEWithLogitsLoss()\n",
      "\n",
      "learning rate = 0.000100\n",
      "epoch 0 training class proportions:\n",
      "[0.35   0.0441 0.0941 0.0466 0.0575 0.07   0.0631 0.0626 0.0418 0.0552 0.0423\n",
      " 0.0464 0.0484 0.0409 0.0535 0.043  0.0599 0.042  0.0528 0.0534 0.0469 0.1022\n",
      " 0.0508 0.0581 0.0433 0.24   0.0422 0.0424]\n",
      "epoch 0  train 0.7463  val 0.4404  delta -0.3059  f1 0.5243*  thresh 1.1  time 65.3m\n",
      "\n",
      "epoch 1 training class proportions:\n",
      "[0.3466 0.0461 0.0938 0.0492 0.0571 0.0729 0.0621 0.0621 0.0425 0.0542 0.0406\n",
      " 0.0454 0.0484 0.0425 0.0538 0.0417 0.0602 0.0412 0.0506 0.0524 0.0455 0.1057\n",
      " 0.0479 0.06   0.042  0.2437 0.0436 0.0427]\n",
      "epoch 1  train 0.5420  val 0.3790  delta -0.1630  f1 0.5614*  thresh 1.5  time 65.1m\n",
      "\n",
      "epoch 2 training class proportions:\n",
      "[0.3491 0.0439 0.0953 0.0484 0.0557 0.0701 0.0631 0.0605 0.0414 0.0536 0.0419\n",
      " 0.0462 0.0486 0.0422 0.0543 0.0421 0.0605 0.0423 0.0503 0.0541 0.0444 0.1047\n",
      " 0.0493 0.0592 0.0438 0.2445 0.043  0.0423]\n",
      "epoch 2  train 0.4898  val 0.3594  delta -0.1304  f1 0.5779*  thresh 1.5  time 65.1m\n",
      "\n",
      "epoch 3 training class proportions:\n",
      "[0.3496 0.0449 0.0924 0.0494 0.0577 0.0712 0.0623 0.0612 0.0432 0.0538 0.0415\n",
      " 0.0464 0.0503 0.0394 0.0543 0.0433 0.0602 0.0439 0.0516 0.053  0.0456 0.105\n",
      " 0.0471 0.0585 0.0433 0.2464 0.0416 0.0409]\n",
      "epoch 3  train 0.4579  val 0.3338  delta -0.1241  f1 0.6187*  thresh 1.9  time 65.2m\n",
      "\n",
      "epoch 4 training class proportions:\n",
      "[0.3483 0.044  0.0935 0.0479 0.056  0.0697 0.0651 0.062  0.041  0.0546 0.0417\n",
      " 0.0458 0.0493 0.0412 0.0551 0.0424 0.061  0.0433 0.0515 0.0519 0.0447 0.1045\n",
      " 0.0487 0.0577 0.0436 0.2437 0.0436 0.0426]\n",
      "epoch 4  train 0.4347  val 0.3417  delta -0.0930  f1 0.6094   thresh 1.6  time 65.6m\n",
      "\n",
      "learning rate = 0.000050\n",
      "epoch 5 training class proportions:\n",
      "[0.3484 0.0444 0.0935 0.048  0.0573 0.071  0.0641 0.0606 0.0419 0.0551 0.0431\n",
      " 0.0459 0.0486 0.0419 0.0538 0.0409 0.0588 0.0412 0.0517 0.053  0.0442 0.104\n",
      " 0.0502 0.0588 0.0426 0.2468 0.0433 0.0421]\n",
      "epoch 5  train 0.3917  val 0.3094  delta -0.0823  f1 0.6628*  thresh 1.5  time 65.5m\n",
      "\n",
      "epoch 6 training class proportions:\n",
      "[0.3483 0.0441 0.0926 0.0484 0.0571 0.0705 0.0633 0.0617 0.0434 0.0564 0.0426\n",
      " 0.046  0.0475 0.0425 0.054  0.04   0.0603 0.0419 0.0496 0.0533 0.0447 0.1066\n",
      " 0.0487 0.0584 0.0445 0.241  0.0441 0.0422]\n",
      "epoch 6  train 0.3753  val 0.3178  delta -0.0575  f1 0.6644*  thresh 1.8  time 65.2m\n",
      "\n",
      "epoch 7 training class proportions:\n",
      "[0.3481 0.0439 0.0968 0.0483 0.0565 0.0715 0.0636 0.0611 0.0429 0.0537 0.0417\n",
      " 0.0473 0.0485 0.0401 0.053  0.0439 0.0602 0.0418 0.0513 0.0536 0.046  0.1039\n",
      " 0.0491 0.0588 0.0433 0.2435 0.044  0.0407]\n",
      "epoch 7  train 0.3593  val 0.3144  delta -0.0449  f1 0.6463   thresh 1.7  time 65.1m\n",
      "\n",
      "epoch 8 training class proportions:\n",
      "[0.3452 0.044  0.0943 0.0496 0.0558 0.0705 0.0647 0.0593 0.0425 0.0542 0.0417\n",
      " 0.0465 0.0485 0.0416 0.0533 0.0425 0.0598 0.0444 0.0508 0.0526 0.0454 0.1062\n",
      " 0.0493 0.0607 0.0433 0.2403 0.0429 0.0434]\n",
      "epoch 8  train 0.3508  val 0.3275  delta -0.0233  f1 0.6157   thresh 1.3  time 65.4m\n",
      "\n",
      "epoch 9 training class proportions:\n",
      "[0.3421 0.0449 0.0966 0.0485 0.0569 0.0723 0.0618 0.0613 0.0411 0.0553 0.0423\n",
      " 0.0473 0.0489 0.0424 0.0536 0.0414 0.0597 0.0416 0.0516 0.0535 0.0443 0.1048\n",
      " 0.048  0.0584 0.0431 0.2411 0.042  0.0429]\n",
      "epoch 9  train 0.3423  val 0.3343  delta -0.0080  f1 0.6017   thresh 1.3  time 65.5m\n",
      "\n",
      "learning rate = 0.000025\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "clip = 20.\n",
    "\n",
    "for f in range(nfold):\n",
    "    \n",
    "    if f != fold: continue\n",
    "    \n",
    "    print('')\n",
    "    print('*'*50)\n",
    "    print(mname + ' fold ' + str(fold))\n",
    "    print('*'*50)\n",
    "    bname = mname+'/'+'best_'+str(fold)+'.pth'\n",
    "    \n",
    "    # Network definition\n",
    "    net = Resnet(num_classes=28)\n",
    "    \n",
    "    print(\"Number of parameters:\",\"{:,}\".format(count_parameters(net)))\n",
    "    # print(p.status())\n",
    "\n",
    "    # classification loss\n",
    "    # criterion = utils.cross_entropy2d\n",
    "    # criterion = torch.nn.BCELoss()\n",
    "    # criterion = dice_loss\n",
    "    # criterion = BCELoss2d()\n",
    "    # criterion = CombinedLoss(is_weight=False).cuda()\n",
    "    # criterion = L.lovasz_hinge\n",
    "    # criterion = L.lovasz2_bce1\n",
    "    # criterion = L.lovasz_hinge\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "    # criterion = FocalLoss()\n",
    "    # criterion = ThreeWayLoss()\n",
    "\n",
    "    # this gets overridden in loop below\n",
    "    pw = torch.tensor([10.]).float().to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pw)\n",
    "#     criterion = Smooth_L1_LossW(pos_weight=pw)\n",
    "    # criterion = F.smooth_l1_loss\n",
    "    \n",
    "    # starting values for inverse positive weights\n",
    "    ipw = np.array([0.3305, 0.043,  0.1031, 0.0472, 0.0525,\n",
    "                       0.0852, 0.0579, 0.0508, 0.0413, 0.0569,\n",
    "                       0.0406, 0.0439, 0.0432, 0.0405, 0.0549,\n",
    "                       0.0424, 0.0749, 0.0428, 0.0517, 0.0512,\n",
    "                       0.04,   0.0812, 0.0437, 0.0678, 0.0414,\n",
    "                       0.181,  0.0422, 0.0427])\n",
    "\n",
    "    if resume_epoch == 0:\n",
    "        if len(mname0):\n",
    "            bname0 = mname0+'/'+'best_'+str(fold)+'.pth'\n",
    "            print(f'Initializing weights from {bname0}')\n",
    "            # load best model\n",
    "            best = torch.load(bname0, map_location='cpu')\n",
    "            # print(best.keys())\n",
    "            net.load_state_dict(best, strict=False)\n",
    "    else:\n",
    "        print(f'Initializing weights from {bname}')\n",
    "        # load best model\n",
    "        best = torch.load(bname, map_location='cpu')\n",
    "        # print(best.keys())\n",
    "        net.load_state_dict(best, strict=False)\n",
    "\n",
    "    if gpu_id >= 0:\n",
    "        print('Using GPU: {} '.format(gpu_id))\n",
    "        torch.cuda.set_device(device=gpu_id)\n",
    "        # net.cuda()\n",
    "        net.train()\n",
    "        net.to(device)\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    # Logging into Tensorboard\n",
    "    # log_dir = os.path.join(save_dir, 'models', datetime.now().strftime('%b%d_%H-%M-%S') + '_' + socket.gethostname())\n",
    "    log_dir = os.path.join('tensorboard', mname + '_' + str(fold))\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # Use the following optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=p['lr'])\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=p['lr'], momentum=p['momentum'],\n",
    "#                           weight_decay=p['wd'])\n",
    "#     optimizer = torch.optim.Adadelta(net.parameters(), lr=1.0, rho=0.9, eps=1e-06,\n",
    "#                                      weight_decay=1e-6)\n",
    "    p['optimizer'] = str(optimizer)\n",
    "\n",
    "#     scheduler = LambdaLR(optimizer, lr_lambda=cyclic_lr)\n",
    "#     scheduler.base_lrs = list(map(lambda group: 1.0, optimizer.param_groups))  \n",
    "#     scheduler = ReduceLROnPlateau(optimizer, factor=0.2, patience=5, verbose=True, \n",
    "#                                   threshold=0.0, threshold_mode='abs')\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=p['step_size'], gamma=p['gamma'])\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    file_list_val = [f for f in file_list if folds[f]==fold]\n",
    "    file_list_train = [f for f in file_list if f not in file_list_val]\n",
    "    print('Training on ' + str(len(file_list_train)) + \\\n",
    "          ' and validating on ' + str(len(file_list_val)))\n",
    "    \n",
    " \n",
    "    db_train = MultiBandMultiLabelDataset(df.loc[file_list_train], \n",
    "                                          base_path=PATH_TO_TRAIN,\n",
    "#                                           augmentator=train_aug,\n",
    "                                          image_transform=composed_transforms_train)\n",
    "    \n",
    "    db_val = MultiBandMultiLabelDataset(df.loc[file_list_val], \n",
    "                                        base_path=PATH_TO_TRAIN,\n",
    "#                                         augmentator=test_aug,\n",
    "                                        image_transform=composed_transforms_test)\n",
    "\n",
    "#     db_x = MultiBandMultiLabelDataset(dfx, \n",
    "#                                       base_path=PATH_TO_EXTERNAL,\n",
    "# #                                       augmentator=train_aug,\n",
    "#                                       image_transform=composed_transforms_train,\n",
    "#                                       external=1)\n",
    "    \n",
    "    db_xx = MultiBandMultiLabelDataset(dfxx, \n",
    "                                      base_path=PATH_TO_EXTERNAL2,\n",
    "#                                       augmentator=train_aug,\n",
    "                                      image_transform=composed_transforms_train,\n",
    "                                      external=2)\n",
    "    \n",
    "    db_pseudo = MultiBandMultiLabelDataset(ssp, \n",
    "                                        base_path=PATH_TO_TEST, \n",
    "#                                         augmentator=test_aug,\n",
    "                                        image_transform=composed_transforms_train)\n",
    "\n",
    "    db_test = MultiBandMultiLabelDataset(ss, train_mode=False,\n",
    "                                        base_path=PATH_TO_TEST, \n",
    "#                                         augmentator=test_aug,\n",
    "                                        image_transform=composed_transforms_test)\n",
    "\n",
    "    # construct sampling weights as max of reciprocal class frequencies\n",
    "    ylist = [t.split(' ') for t in db_train.images_df.Target]\n",
    "    # print(ylist[:5])\n",
    "    # build one-hot matrix\n",
    "    y = np.zeros((db_train.images_df.shape[0],28))\n",
    "    for i,l in enumerate(ylist):\n",
    "        for j in range(len(l)): y[i,int(l[j])] = 1.\n",
    "    # print(y[:20])\n",
    "    # sampling weights \n",
    "    w = 1.0/np.mean(y,axis=0)\n",
    "    # w = np.clip(w, 0., 1000.)\n",
    "    np.set_printoptions(precision=4,linewidth=80,suppress=True)\n",
    "    print('Sampling weights:')\n",
    "    print(w)\n",
    "    # replace 1s with weights in the one-hot matrix\n",
    "    for i,l in enumerate(ylist):\n",
    "        for j in range(len(l)): y[i,int(l[j])] = w[int(l[j])]\n",
    "    # print(y[:10])\n",
    "    # use maximum weight when there are multiple targets\n",
    "    samples_weight = np.amax(y,axis=1)\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'),\n",
    "                                    len(samples_weight))\n",
    "    \n",
    "#     # construct similar sampler for external data\n",
    "#     # construct sampling weights as max of reciprocal class frequencies\n",
    "#     ylistx = [t.split(' ') for t in db_x.images_df.Target]\n",
    "#     # print(ylist[:5])\n",
    "#     # build one-hot matrix\n",
    "#     yx = np.zeros((db_x.images_df.shape[0],28))\n",
    "#     for i,l in enumerate(ylistx):\n",
    "#         for j in range(len(l)): yx[i,int(l[j])] = 1.\n",
    "#     # sampling weights \n",
    "#     wx = 1.0/np.mean(yx,axis=0)\n",
    "#     wx = np.clip(wx, 0., 3000.)\n",
    "#     np.set_printoptions(precision=4,linewidth=80,suppress=True)\n",
    "#     print('Sampling weights external:')\n",
    "#     print(wx)\n",
    "#     # replace 1s with weights in the one-hot matrix\n",
    "#     for i,l in enumerate(ylistx):\n",
    "#         for j in range(len(l)): yx[i,int(l[j])] = wx[int(l[j])]\n",
    "#     # print(y[:10])\n",
    "#     # use maximum weight when there are multiple targets\n",
    "#     samples_weightx = np.amax(yx,axis=1)\n",
    "#     samples_weightx = torch.from_numpy(samples_weightx)\n",
    "#     samplerx = WeightedRandomSampler(samples_weightx.type('torch.DoubleTensor'),\n",
    "#                                     len(samples_weightx))\n",
    "\n",
    "    # construct similar sampler for external data 2\n",
    "    # construct sampling weights as max of reciprocal class frequencies\n",
    "    ylistxx = [t.split(' ') for t in db_xx.images_df.Target]\n",
    "    # print(ylist[:5])\n",
    "    # build one-hot matrix\n",
    "    yxx = np.zeros((db_xx.images_df.shape[0],28))\n",
    "    for i,l in enumerate(ylistxx):\n",
    "        for j in range(len(l)): yxx[i,int(l[j])] = 1.\n",
    "    # sampling weights \n",
    "    wxx = 1.0/np.mean(yxx,axis=0)\n",
    "    wxx = np.clip(wxx, 0., 3000.)\n",
    "    np.set_printoptions(precision=4,linewidth=80,suppress=True)\n",
    "    print('Sampling weights external2:')\n",
    "    print(wxx)\n",
    "    # replace 1s with weights in the one-hot matrix\n",
    "    for i,l in enumerate(ylistxx):\n",
    "        for j in range(len(l)): yxx[i,int(l[j])] = wxx[int(l[j])]\n",
    "    # print(y[:10])\n",
    "    # use maximum weight when there are multiple targets\n",
    "    samples_weightxx = np.amax(yxx,axis=1)\n",
    "    samples_weightxx = torch.from_numpy(samples_weightxx)\n",
    "    samplerxx = WeightedRandomSampler(samples_weightxx.type('torch.DoubleTensor'),\n",
    "                                    len(samples_weightxx))\n",
    "\n",
    "    # construct similar sampler for pseudo-labelling\n",
    "    # construct sampling weights as max of reciprocal class frequencies\n",
    "    ylistp = [[] if isinstance(t,float) else t.split(' ') for t in db_pseudo.images_df.Target]\n",
    "    # print(ylist[:5])\n",
    "    # build one-hot matrix\n",
    "    yp = np.zeros((db_pseudo.images_df.shape[0],28))\n",
    "    for i,l in enumerate(ylistp):\n",
    "        for j in range(len(l)): yp[i,int(l[j])] = 1.\n",
    "    # sampling weights \n",
    "    wp = 1.0/np.mean(yp,axis=0)\n",
    "    wp = np.clip(wp, 0., 3000.)\n",
    "    np.set_printoptions(precision=4,linewidth=80,suppress=True)\n",
    "    print('Sampling weights pseudo:')\n",
    "    print(wp)\n",
    "    # replace 1s with weights in the one-hot matrix\n",
    "    for i,l in enumerate(ylistp):\n",
    "        for j in range(len(l)): yp[i,int(l[j])] = wp[int(l[j])]\n",
    "    # print(y[:10])\n",
    "    # use maximum weight when there are multiple targets\n",
    "    samples_weightp = np.amax(yp,axis=1)\n",
    "    samples_weightp = torch.from_numpy(samples_weightp)\n",
    "    samplerp = WeightedRandomSampler(samples_weightp.type('torch.DoubleTensor'),\n",
    "                                    len(samples_weightp))\n",
    "\n",
    "    trainloader = DataLoader(db_train, collate_fn=db_train.collate_func,\n",
    "                             batch_size=3*p['trainBatch']//8, sampler=sampler,\n",
    "                             num_workers=6)\n",
    "    \n",
    "#     xloader = DataLoader(db_x, collate_fn=db_x.collate_func,\n",
    "#                              batch_size=p['trainBatch']//8, sampler=samplerx,\n",
    "#                              num_workers=2)\n",
    "\n",
    "    xxloader = DataLoader(db_xx, collate_fn=db_xx.collate_func,\n",
    "                             batch_size=3*p['trainBatch']//8, sampler=samplerxx,\n",
    "                             num_workers=6)\n",
    "    \n",
    "    pseudoloader = DataLoader(db_pseudo, collate_fn=db_pseudo.collate_func,\n",
    "                             batch_size=p['trainBatch']//4, sampler=samplerp,\n",
    "                             num_workers=4)\n",
    "    \n",
    "    valloader = DataLoader(db_val, collate_fn=db_train.collate_func,\n",
    "                           batch_size=p['testBatch'], shuffle=False,\n",
    "                          num_workers=16)\n",
    "    \n",
    "    testloader = DataLoader(db_test, collate_fn=db_test.collate_func,\n",
    "                       batch_size=p['testBatch'], shuffle=False,\n",
    "                      num_workers=16)\n",
    "   \n",
    "#     xloader_enum = enumerate(xloader)\n",
    "    xxloader_enum = enumerate(xxloader)\n",
    "    pseudoloader_enum = enumerate(pseudoloader)\n",
    "    \n",
    "    \n",
    "#     # function to generate batches within ImageLoader with no arguments\n",
    "#     def load_training_batch():\n",
    "#         examples_batch = random.sample(list(db_train.images_df.Id.values), p['trainBatch'])\n",
    "#         blist = [db_train[ex] for ex in examples_batch]\n",
    "#         images = [b[0] for b in blist]\n",
    "#         targets = [b[1] for b in blist]\n",
    "#         return Batch(identifiers=None, images=images, targets=targets)\n",
    "\n",
    "#     img_loader = ImageLoader(load_training_batch, nb_workers=6)\n",
    "#     bg_augmenter = BackgroundAugmenter(seq, img_loader.queue, nb_workers=8)\n",
    "\n",
    "    utils.generate_param_report(os.path.join(save_dir, mname + '.txt'), p)\n",
    "\n",
    "    # number of batches\n",
    "    num_img_tr = len(trainloader)\n",
    "    num_img_ts = len(valloader)\n",
    "    \n",
    "    print('Image size:', final_size)\n",
    "    print('Batch size:', p['trainBatch'])\n",
    "    print('Batches per epoch:', num_img_tr)\n",
    "    print('Epochs:', nEpochs)\n",
    "    print('Loss:', criterion)\n",
    "    # print('Learning rate: ', p['lr'])\n",
    "    print('')\n",
    "   \n",
    "    running_loss_tr = 0.0\n",
    "    running_loss_ts = 0.0\n",
    "    aveGrad = 0\n",
    "    bname = mname+'/'+'best_'+str(fold)+'.pth'\n",
    "    # print(\"Training Network\")\n",
    "    history = {}\n",
    "    history['epoch'] = []\n",
    "    history['train'] = []\n",
    "    history['val'] = []\n",
    "    history['delta'] = []\n",
    "    history['f1'] = []\n",
    "    history['time'] = []\n",
    "    best_val = -999\n",
    "    bad_epochs = 0\n",
    "    start_time = timeit.default_timer()\n",
    "    total_time = 0\n",
    "    prev_lr = 999\n",
    "\n",
    "    # Main Training and Testing Loop\n",
    "    for epoch in range(resume_epoch, nEpochs):\n",
    "\n",
    "#         if (epoch > 0) and (epoch % p['epoch_size'] == 0):\n",
    "#             lr_ = utils.lr_poly(p['lr'], epoch, nEpochs, 0.9)\n",
    "#             print('(poly lr policy) learning rate', lr_)\n",
    "#             print('')\n",
    "#             optimizer = optim.SGD(net.parameters(), lr=lr_, momentum=p['momentum'],\n",
    "#                                   weight_decay=p['wd'])\n",
    "\n",
    "        scheduler.step()\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        if lr != prev_lr: \n",
    "            print('learning rate = %.6f' % lr)\n",
    "            prev_lr = lr\n",
    "\n",
    "        net.train()\n",
    "        \n",
    "        train_loss = []\n",
    "        ns = 0\n",
    "        \n",
    "        # for ii in range(num_img_tr):\n",
    "        for ii, sample_batched in enumerate(trainloader):\n",
    "            \n",
    "            inputs, gts = sample_batched[0], sample_batched[1]\n",
    "            \n",
    "#             # external data\n",
    "#             try:\n",
    "#                 _, xbatch = next(xloader_enum)\n",
    "#             except:\n",
    "#                 xloader_enum = enumerate(xloader)\n",
    "#                 _, xbatch = next(xloader_enum)\n",
    "            \n",
    "#             inputsx, gtsx = xbatch[0], xbatch[1]\n",
    "            \n",
    "            # external data 2\n",
    "            try:\n",
    "                _, xxbatch = next(xxloader_enum)\n",
    "            except:\n",
    "                xxloader_enum = enumerate(xxloader)\n",
    "                _, xxbatch = next(xxloader_enum)\n",
    "            \n",
    "            inputsxx, gtsxx = xxbatch[0], xxbatch[1]\n",
    "\n",
    "            # pseudo-labelling\n",
    "            try:\n",
    "                _, pbatch = next(pseudoloader_enum)\n",
    "            except:\n",
    "                pseudoloader_enum = enumerate(pseudoloader)\n",
    "                _, pbatch = next(pseudoloader_enum)\n",
    "            \n",
    "            inputsp, gtsp = pbatch[0], pbatch[1]\n",
    "\n",
    "#             inputs = torch.cat([inputs,inputsx,inputsxx],0)\n",
    "#             gts = torch.cat([gts,gtsx,gtsxx],0)\n",
    "            inputs = torch.cat([inputs,inputsxx,inputsp],0)\n",
    "            gts = torch.cat([gts,gtsxx,gtsp],0)\n",
    "                       \n",
    "            # use green channel as ground truth mask for current classes\n",
    "#             gi = inputs.numpy()[:,1].copy()\n",
    "#             print('gi stats', gi.shape, gi.min(), gi.mean(), gi.max())\n",
    "            bsize = inputs.shape[0]\n",
    "            gmask = np.zeros((bsize, num_classes, gsize, gsize)).astype(float)\n",
    "            for jj in range(bsize):\n",
    "#                 print('gij before denorm', gi[jj].shape, gi[jj].min(),gi[jj].mean(), gi[jj].max())\n",
    "#                 gij = gi[jj]*istd[1] + imean[1]\n",
    "#                 print('gij after denorm', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "#                 print('gij before filter', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "#                 gij = gaussian_filter(gij,gstd)\n",
    "#                 print('gij after filter', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "#                 gij = (gij > gthresh).astype(float)\n",
    "#                 print('gij after thresh', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "                gr = 1.0\n",
    "#                 gr = cv2.resize(gij, (gsize,gsize), interpolation=interp)\n",
    "#                 grmin = gr.min()\n",
    "#                 grmax = gr.max()\n",
    "# #                 print('gr before rescale', gr.shape, grmin, gr.mean(), grmax)\n",
    "#                 gr = (gr - grmin)/(grmax - grmin + 1e-6)\n",
    "#                 print('gr after rescale', gr.shape, gr.min(), gr.mean(), gr.max())\n",
    "#                 gr = (gr > gthresh).astype(int)\n",
    "#                 print('gr after thresh', gr.shape, gr.min(), gr.mean(), gr.max())\n",
    "#                 gr = binary_dilation(gr).astype(int)\n",
    "#                 print('gr after dilation', gr.shape, gr.min(), gr.mean(), gr.max())\n",
    "#                 gin = gi[jj]\n",
    "#                 gin = (gin - gin.min())/(gin.max()-gin.min()+1e-6)\n",
    "#                 grn = cv2.resize(gin, (gsize,gsize), interpolation=interp)\n",
    "#                 print('grn stats', grn.shape, grn.min(), grn.mean(), grn.max())\n",
    "#                 gr = (gr > gthresh).astype(bool).astype(int)\n",
    "#                 print('gr mean batch', jj, np.mean(gr))\n",
    "                for kk in np.nonzero(gts[jj]):\n",
    "                    gmask[jj,kk] = gr\n",
    "#                 print(jj, 'y', gts[jj])\n",
    "#                 print(jj, 'gmask mean', np.average(gmask[jj], axis=(1,2)))\n",
    "            \n",
    "#             print('gmask',gmask.shape,gmask.min(),gmask.mean(),gmask.max())\n",
    "            gmask = torch.from_numpy(gmask).float()\n",
    "            \n",
    "            # keep track of sampling proportions\n",
    "            gt = gts.cpu().detach().numpy()\n",
    "            gs = np.sum(gt,axis=0)\n",
    "            if ii==0: gtsum = gs\n",
    "            else: gtsum += gs\n",
    "            ns += bsize\n",
    "\n",
    "            inputs = inputs.type(torch.float).to(device)\n",
    "            gts = gts.to(device)\n",
    "            gmask = gmask.to(device)\n",
    "            \n",
    "#             # use inverse positive weights from previous iteration\n",
    "#             pwb = np.zeros((bsize, num_classes, gsize, gsize))\n",
    "#             for kk in range(num_classes):\n",
    "#                 pwb[:,kk] = 1.0/(ipw[kk] + 1e-5)\n",
    "#             pw = torch.tensor(pwb).float().to(device)\n",
    "#             criterion = Smooth_L1_LossW(pos_weight=pw)\n",
    "\n",
    "            # predictions are heat maps on a probability scale\n",
    "            logits = net(inputs)\n",
    "            logits = torch.clamp(logits, min=-clip, max=clip)\n",
    "            \n",
    "#             class_loss = criterion(logits, gts)\n",
    "            \n",
    "#             first = True\n",
    "#             for kk in range(num_classes):\n",
    "#                 lossk = criterion2(seg[:,kk], gmask[:,kk])\n",
    "#                 # print('seg_loss batch', jj, ' class', kk, lossjk.item())\n",
    "#                 if first: \n",
    "#                     seg_loss = lossk\n",
    "#                     first = False\n",
    "#                 else: seg_loss = seg_loss + lossk\n",
    "#             seg_loss = seg_loss / num_classes\n",
    "\n",
    "             \n",
    "            # print('class_loss', class_loss.item())\n",
    "            # print('seg_loss', seg_loss.item())\n",
    "#             loss = class_loss + 0.5 * seg_loss\n",
    "\n",
    "            loss = criterion(logits, gmask)\n",
    "#             print(ii, loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # adamw\n",
    "            for group in optimizer.param_groups:\n",
    "                for param in group['params']:\n",
    "                    param.data = param.data.add(-p['wd'] * group['lr'], param.data)\n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())                        \n",
    "            running_loss_tr += loss.item()\n",
    "        \n",
    "        print('epoch ' + str(epoch) + ' training class proportions:')\n",
    "        print(gtsum/ns)\n",
    "        \n",
    "        # validation\n",
    "        net.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            val_loss = []\n",
    "            val_predictions = []\n",
    "            val_targets = []\n",
    "        \n",
    "            for ii, sample_batched in enumerate(valloader):\n",
    "\n",
    "                # >>> #In your test loop you can do the following:\n",
    "                # >>> input, target = batch # input is a 5d tensor, target is 2d\n",
    "                # >>> bs, ncrops, c, h, w = input.size()\n",
    "                # >>> result = model(input.view(-1, c, h, w)) # fuse batch size and ncrops\n",
    "                # >>> result_avg = result.view(bs, ncrops, -1).mean(1) # avg over crops\n",
    "\n",
    "                # inputs, gts = sample_batched['image'], sample_batched['gt']\n",
    "                inputs, gts = sample_batched[0], sample_batched[1]\n",
    "        \n",
    "                # fuse batch size and ncrops\n",
    "                bsize, ncrops, c, h, w = inputs.size()\n",
    "                # print(bsize, ncrops, c, h, w)\n",
    "                inputs = inputs.view(-1, c, h, w)\n",
    "\n",
    "                # use thresholded green channel as ground truth mask for current classes\n",
    "#                 gi = inputs.numpy()[:,1].copy()\n",
    "#                 bsize = inputs.shape[0]\n",
    "                gmask = np.zeros((bsize, num_classes, gsize, gsize)).astype(float)\n",
    "        \n",
    "                for jj in range(bsize):\n",
    "    #                 print('gij before denorm', gi[jj].shape, gi[jj].min(),\n",
    "    #                       gi[jj].mean(), gi[jj].max())\n",
    "#                     gij = gi[jj]*istd[1] + imean[1]\n",
    "    #                 print('gij after denorm', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "    #                 print('gij before filter', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "    #                 gij = gaussian_filter(gij,gstd)\n",
    "    #                 print('gij after filter', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "    #                 gij = (gij > gthresh).astype(float)\n",
    "    #                 print('gij after thresh', gij.shape, gij.min(), gij.mean(), gij.max())\n",
    "                    gr = 1.0\n",
    "#                     gr = cv2.resize(gij, (gsize,gsize), interpolation=interp)\n",
    "#                     grmin = gr.min()\n",
    "#                     grmax = gr.max()\n",
    "#     #                 print('gr before rescale', gr.shape, grmin, gr.mean(), grmax)\n",
    "#                     gr = (gr - grmin)/(grmax - grmin + 1e-6)\n",
    "    #                 print('gr after rescale', gr.shape, gr.min(), gr.mean(), gr.max())\n",
    "    #                 gr = (gr > gthresh).astype(int)\n",
    "    #                 print('gr after thresh', gr.shape, gr.min(), gr.mean(), gr.max())\n",
    "    #                 gr = binary_dilation(gr).astype(int)\n",
    "    #                 print('gr after dilation', gr.shape, gr.min(), gr.mean(), gr.max())\n",
    "    #                 gin = gi[jj]\n",
    "    #                 gin = (gin - gin.min())/(gin.max()-gin.min()+1e-6)\n",
    "    #                 grn = cv2.resize(gin, (gsize,gsize), interpolation=interp)\n",
    "    #                 print('grn stats', grn.shape, grn.min(), grn.mean(), grn.max())\n",
    "    #                 gr = (gr > gthresh).astype(bool).astype(int)\n",
    "    #                 print('gr mean batch', jj, np.mean(gr))\n",
    "                    for kk in np.nonzero(gts[jj]):\n",
    "                        gmask[jj,kk] = gr\n",
    "    #                 print(jj, 'y', gts[jj])\n",
    "    #                 print(jj, 'gmask mean', np.average(gmask[jj], axis=(1,2)))\n",
    "\n",
    "                gmask = torch.from_numpy(gmask).float()\n",
    "                \n",
    "                # tta horizontal flip\n",
    "                inputs2 = inputs.numpy()[:,:,:,::-1].copy()\n",
    "                inputs2 = torch.from_numpy(inputs2)\n",
    "\n",
    "                inputs = inputs.type(torch.float).to(device)\n",
    "                inputs2 = inputs2.type(torch.float).to(device)\n",
    "\n",
    "                # predictions are on a logit scale\n",
    "                logits = net(inputs)\n",
    "                # average over crops\n",
    "                logits = logits.view(bsize, ncrops, num_classes, gsize, gsize).mean(1)\n",
    "                logits2 = net(inputs2)\n",
    "                # average over crops\n",
    "                logits2 = logits2.view(bsize, ncrops, num_classes, gsize, gsize).mean(1)\n",
    "                logits2 = logits2.cpu().detach().numpy()[:,:,:,::-1].copy()\n",
    "                logits2 = torch.from_numpy(logits2).to(device)\n",
    "                logits = (logits + logits2)/2.0\n",
    "                \n",
    "                logits = torch.clamp(logits, min=-clip, max=clip)\n",
    "                \n",
    "#                 # use inverse positive weights from this iteration\n",
    "#                 pwb = np.zeros((bsize, num_classes, gsize, gsize))\n",
    "#                 for kk in range(num_classes):\n",
    "#                     pwb[:,kk] = 1.0/(ipw[kk] + 1e-5)\n",
    "#                 pw = torch.tensor(pwb).float().to(device)\n",
    "#                 criterion = Smooth_L1_LossW(pos_weight=pw)\n",
    "                \n",
    "                loss = criterion(logits, gmask.to(device))\n",
    "\n",
    "                running_loss_ts += loss.item()\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                # save results to compute F1 on validation set\n",
    "                preds = logits.cpu().detach().numpy()\n",
    "                gt = gts.cpu().detach().numpy()\n",
    "\n",
    "                val_predictions.append(preds)\n",
    "                val_targets.append(gt)\n",
    "\n",
    "            vps = np.vstack(val_predictions)\n",
    "            vts = np.vstack(val_targets)\n",
    "            \n",
    "            # competition metric\n",
    "            # use percentile to as single prediction for f1\n",
    "            vpsp = np.percentile(vps, gpct, axis=(2,3))\n",
    "            thresholds = np.linspace(-5, 5, 101)\n",
    "            scores = np.array([f1_score(vts, np.int32(vpsp > t),\n",
    "                                    average='macro') for t in thresholds])\n",
    "            threshold_best_index = np.argmax(scores)\n",
    "            vf1 = scores[threshold_best_index]\n",
    "            tbest = thresholds[threshold_best_index]\n",
    "            # vf1 = f1_score(vts,(vps > 0).astype(int), average='macro')\n",
    "\n",
    "            if vf1 > best_val:\n",
    "                star = '*'\n",
    "                best_val = vf1\n",
    "                torch.save(net.state_dict(), bname)\n",
    "                bad_epochs = 0\n",
    "            else:\n",
    "                star = ' '\n",
    "                bad_epochs += 1\n",
    "                \n",
    "            # print progress\n",
    "            # running_loss_ts = running_loss_ts / num_img_ts\n",
    "\n",
    "            tl = np.mean(train_loss)\n",
    "            vl = np.mean(val_loss)\n",
    "\n",
    "            stop_time = timeit.default_timer()\n",
    "            diff_time = (stop_time - start_time)/60.\n",
    "            total_time += diff_time\n",
    "            start_time = timeit.default_timer()\n",
    "\n",
    "            print('epoch %d  train %6.4f  val %6.4f  delta %6.4f  f1 %6.4f%s  thresh %3.1f  time %4.1f%s\\n' % \\\n",
    "                  (epoch, tl, vl, vl-tl, vf1, star, tbest, diff_time, 'm'))\n",
    "            writer.add_scalar('loss', tl, epoch)\n",
    "            writer.add_scalar('val_loss', vl, epoch)\n",
    "            writer.add_scalar('delta', vl-tl, epoch)\n",
    "            writer.add_scalar('val_f1', vf1, epoch)\n",
    "            writer.add_scalar('thresh', tbest, epoch)\n",
    "            writer.add_scalar('time', diff_time, epoch)\n",
    "            # print('Running Loss: %f\\n' % running_loss_ts)\n",
    "            # print('Mean Loss: %f\\n' % np.mean(val_loss))\n",
    "            running_loss_tr = 0\n",
    "            running_loss_ts = 0\n",
    "\n",
    "            history['epoch'].append(epoch)\n",
    "            history['train'].append(tl)\n",
    "            history['val'].append(vl)\n",
    "            history['f1'].append(vf1)\n",
    "            history['time'].append(diff_time)\n",
    "\n",
    "            if bad_epochs > p['patience']:\n",
    "                print('early stopping, best validation loss %6.4f, total time %4.1f minutes \\n' % \\\n",
    "                      (best_val, total_time))\n",
    "                break\n",
    "            \n",
    "    writer.close()\n",
    "\n",
    "    # plot history\n",
    "    fig, (ax_loss) = plt.subplots(1, 1, figsize=(8,4))\n",
    "    ax_loss.plot(history['epoch'], history['train'], label=\"Train loss\")\n",
    "    ax_loss.plot(history['epoch'], history['val'], label=\"Validation loss\")\n",
    "    plt.show()\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_pseudo.images_df.Target[2].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "best = torch.load(bname, map_location='cpu')\n",
    "# print(best.keys())\n",
    "net.load_state_dict(best)\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # predict validation set\n",
    "    val_logits = []\n",
    "    val_y = []\n",
    "    # for image, mask in tqdm.tqdm(data.DataLoader(dataset_val, batch_size = 30)):\n",
    "    batch = 0\n",
    "    for image, y in valloader:\n",
    "        \n",
    "        # fuse batch size and ncrops\n",
    "        bsize, ncrops, c, h, w = image.size()\n",
    "        image = image.view(-1, c, h, w)\n",
    "        \n",
    "        # test-time augmentation with horizontal flipping\n",
    "        image2 = image.numpy()[:,:,:,::-1].copy()\n",
    "        image2 = torch.from_numpy(image2)\n",
    "        image = image.type(torch.float).to(device)\n",
    "        image2 = image2.type(torch.float).to(device)\n",
    "        logits = net(image)\n",
    "        # average over crops\n",
    "        logits = logits.view(bsize, ncrops, num_classes, gsize, gsize).mean(1)\n",
    "        logits = logits.cpu().detach().numpy()\n",
    "        logits2 = net(image2)\n",
    "        # average over crops\n",
    "        logits2 = logits2.view(bsize, ncrops, num_classes, gsize, gsize).mean(1)\n",
    "        logits2 = logits2.cpu().detach().numpy()\n",
    "        logits2 = logits2[:,:,:,::-1]\n",
    "        logits = (logits + logits2)/2.0\n",
    "             \n",
    "        val_logits.append(logits)\n",
    "\n",
    "        y = y.cpu().detach().numpy()\n",
    "        val_y.append(y)\n",
    "\n",
    "        batch += 1\n",
    "\n",
    "    vls = np.vstack(val_logits)\n",
    "    vys = np.vstack(val_y)\n",
    "\n",
    "    print(vls.shape, vys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits.shape,logits.min(),logits.mean(),logits.max())\n",
    "print(logits2.shape,logits2.min(),logits2.mean(),logits2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 15\n",
    "vpc = np.array([np.clip(logits.flatten(),0.,clip), np.clip(logits2.flatten(),0.,clip)])\n",
    "\n",
    "# tpsf = np.hstack([c.reshape((-1,1)) for c in tps])\n",
    "print(vpc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(vpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out-of-fold predictions\n",
    "oof_ids = file_list_val\n",
    "poof = vls.copy()\n",
    "yoof = vys.copy()\n",
    "\n",
    "oof = [oof_ids, poof, yoof]\n",
    "fname = 'oof/'+mname+'_'+str(fold)+'.pkl'\n",
    "pickle.dump(oof,open(fname,'wb'))\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for best threshold\n",
    "# note predictions and thresholds are on logit scale\n",
    "vlsp = np.percentile(vls, gpct, axis=(2,3))\n",
    "# vlsp = np.average(vls, axis=(2,3))\n",
    "\n",
    "thresholds = np.linspace(-5, 10, 151)\n",
    "scores = np.array([f1_score(vys, (vlsp > t).astype(int), average='macro') \\\n",
    "                 for t in thresholds])\n",
    "\n",
    "threshold_best_index = np.argmax(scores)\n",
    "score_best = scores[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "print('')\n",
    "print('f1_best',score_best)\n",
    "print('threshold_best',threshold_best)\n",
    "print('')\n",
    "\n",
    "plt.plot(thresholds, scores)\n",
    "plt.plot(threshold_best, score_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1\")\n",
    "plt.title(\"Threshold vs F1 ({}, {})\".format(threshold_best, score_best))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = vlsp.flatten()\n",
    "print(vf.min(),vf.mean(),vf.max(),vf.shape)\n",
    "sns.distplot(vf)\n",
    "plt.title(\"Distribution of Predictions (Logit Scale) for Fold \" + str(fold+1))\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(vys,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = [confusion_matrix(vys[:,i], (vlsp[:,i] > threshold_best).astype(int)) \\\n",
    "       for i in range(vys.shape[1])]\n",
    "fm = [f1_score(vys[:,i], (vlsp[:,i] > threshold_best).astype(int)) \\\n",
    "       for i in range(vys.shape[1])]\n",
    "for i in range(vys.shape[1]):\n",
    "    print(LABEL_MAP[i])\n",
    "    print(cm[i], '%4.2f' % fm[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fm1 = [f for f in fm if f > 0]\n",
    "# print(len(fm1))\n",
    "# print(np.mean(fm1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1b = np.array([f1_score(y, (l > threshold_best).astype(int)) \\\n",
    "                 for y,l in zip(vys,vlsp)])\n",
    "print(f1b.min(),f1b.mean(),f1b.max())\n",
    "sns.distplot(f1b)\n",
    "plt.title(\"Distribution of Sample F1 Scores for Fold \" + str(fold))\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation images with scores\n",
    "# sort from worst to best\n",
    "order = f1b.argsort()\n",
    "max_images = 90\n",
    "# max_images = len(file_list_val)\n",
    "start = 0\n",
    "# start = 200\n",
    "grid_width = 10\n",
    "grid_height = int(max_images / grid_width)\n",
    "# print(max_images,grid_height,grid_width)\n",
    "\n",
    "file_list_val_reordered = [file_list_val[order[i]] for i,f in enumerate(file_list_val)]\n",
    "\n",
    "for i, idx in enumerate([file_list_val_reordered[i] for i in range(start,(start+max_images))]):\n",
    "    imod = i % 30\n",
    "    if imod == 0:\n",
    "        fig, axs = plt.subplots(3, 10, figsize=(30, 10))\n",
    "    img, y = db_val[order[i]]\n",
    "\n",
    "    img = img[0].data.numpy()[1]\n",
    "    img = img[y_min_pad:(image_size - y_max_pad), x_min_pad:(image_size - x_max_pad)]\n",
    "\n",
    "    true = np.nonzero(vys[order][start+i])\n",
    "    true_str = ' '.join(map(str, true))\n",
    "    pred = np.nonzero((vlsp[order][start+i] > threshold_best).astype(int))\n",
    "    pred_str = ' '.join(map(str, pred))\n",
    "    ax = axs[int(imod / grid_width), imod % grid_width]\n",
    "    ax.imshow(img, cmap='Greens')\n",
    "    ax.set_title(str(i) + '   ' + idx[:13] + '\\n' + true_str + '  ' + pred_str)\n",
    "    # ax.set_xlabel(str(round(ioub[i], 3)))\n",
    "    ax.set_xlabel('%4.2f' % (f1b[order][start+i]))\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    if imod == 29:\n",
    "        # plt.suptitle(\"Green: salt, Red: prediction. Top-left: coverage class, Top-right: salt coverage, Bottom-left: depth, Bottom-right: IOU\")\n",
    "        plt.show()\n",
    "        plt.gcf().clear()\n",
    "        gc.collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ss.head())\n",
    "print(ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 20\n",
    "with torch.no_grad():\n",
    "    print('predicting test set for bagging')\n",
    "    tp = {}\n",
    "    for i in range(8): tp[i] = []\n",
    "    \n",
    "    # 8-way TTA\n",
    "    # for image in tqdm.tqdm(data.DataLoader(test_dataset, batch_size = 30)):\n",
    "    for image in testloader:\n",
    "        \n",
    "        # fuse batch size and ncrops\n",
    "        bsize, ncrops, c, h, w = image[0].size()\n",
    "        image = image[0].view(-1, c, h, w)\n",
    "        \n",
    "        i = 0\n",
    "        image1 = image.numpy().copy()\n",
    "        # move channels last for augmentation\n",
    "        image1 = np.transpose(image1, (0, 2, 3, 1))\n",
    "       \n",
    "        image = image.type(torch.float).to(device)\n",
    "        logits = net(image)\n",
    "        # average over crops\n",
    "        logits = logits.view(bsize, ncrops, num_classes, gsize, gsize).mean(1)\n",
    "        logits = logits.cpu().detach().numpy()\n",
    "        logits = np.clip(logits,-clip,clip)\n",
    "        tp[i].append(logits)\n",
    "        i += 1\n",
    "       \n",
    "        for degrees in [90, 180, 270]:\n",
    "            IAA = iaa.Affine(rotate=degrees)\n",
    "            image2 = np.array([IAA.augment_image(imi) for imi in image1])\n",
    "            # move channels first for pytorch\n",
    "            image2 = np.transpose(image2, (0, 3, 1, 2))\n",
    "            image2 = torch.from_numpy(image2)\n",
    "            image2 = image2.type(torch.float).to(device)\n",
    "            logits2 = net(image2)\n",
    "            # average over crops\n",
    "            logits2 = logits2.view(bsize, ncrops, num_classes, gsize, gsize).mean(1)\n",
    "            logits2 = logits2.cpu().detach().numpy()\n",
    "            logits2 = np.clip(logits2,-clip,clip)\n",
    "            IAA = iaa.Affine(rotate=-degrees)\n",
    "            logits2 = np.transpose(logits2, (0, 2, 3, 1))\n",
    "            logits2 = np.array([IAA.augment_image(imi) for imi in logits2])\n",
    "            logits2 = np.transpose(logits2, (0, 3, 1, 2))\n",
    "            tp[i].append(logits2)\n",
    "            i += 1\n",
    "        \n",
    "        # horizontally flip image1\n",
    "        IAA = iaa.Fliplr(1.0)\n",
    "        image1 = np.array([IAA.augment_image(imi) for imi in image1])\n",
    "        image2 = np.transpose(image1, (0, 3, 1, 2))\n",
    "        image2 = torch.from_numpy(image2)\n",
    "        image2 = image2.type(torch.float).to(device)\n",
    "        logits2 = net(image2)\n",
    "        # average over crops\n",
    "        logits2 = logits2.view(bsize, ncrops, num_classes, gsize, gsize).mean(1)\n",
    "        logits2 = logits2.cpu().detach().numpy()\n",
    "        logits2 = np.clip(logits2,-clip,clip)\n",
    "        logits2 = np.transpose(logits2, (0, 2, 3, 1))\n",
    "        logits2 = np.array([IAA.augment_image(imi) for imi in logits2])\n",
    "        logits2 = np.transpose(logits2, (0, 3, 1, 2))\n",
    "        tp[i].append(logits2)\n",
    "        i += 1\n",
    "        \n",
    "        # rotations again on flipped image\n",
    "        for degrees in [90, 180, 270]:\n",
    "            IAA = iaa.Affine(rotate=degrees)\n",
    "            image2 = np.array([IAA.augment_image(imi) for imi in image1])\n",
    "            image2 = np.transpose(image2, (0, 3, 1, 2))\n",
    "            image2 = torch.from_numpy(image2)\n",
    "            image2 = image2.type(torch.float).to(device)\n",
    "            logits2 = net(image2)\n",
    "            # average over crops\n",
    "            logits2 = logits2.view(bsize, ncrops, num_classes, gsize, gsize).mean(1)\n",
    "            logits2 = logits2.cpu().detach().numpy()\n",
    "            logits2 = np.clip(logits2,-clip,clip)\n",
    "            IAA = iaa.Affine(rotate=-degrees)\n",
    "            logits2 = np.transpose(logits2, (0, 2, 3, 1))\n",
    "            logits2 = np.array([IAA.augment_image(imi) for imi in logits2])\n",
    "            IAA = iaa.Fliplr(1.0)\n",
    "            logits2 = np.array([IAA.augment_image(imi) for imi in logits2])\n",
    "            logits2 = np.transpose(logits2, (0, 3, 1, 2))\n",
    "            tp[i].append(logits2)\n",
    "            i += 1\n",
    "         \n",
    "    tps = np.array([np.vstack(tp[i]) for i in range(8)])\n",
    "    print(tps.shape)\n",
    "\n",
    "tpsf = np.hstack([c.reshape((-1,1)) for c in tps])\n",
    "print(tpsf.shape)\n",
    "\n",
    "np.set_printoptions(precision=3,linewidth=100)\n",
    "print(np.corrcoef(tpsf, rowvar=False))\n",
    "\n",
    "ptest = np.median(tps,axis=0)\n",
    "ptesta = np.amax(tps,axis=0)\n",
    "print(ptest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some test images\n",
    "nshow = 50\n",
    "start = np.random.randint(len(test_file_list)-nshow)\n",
    "stop = start + nshow\n",
    "grid_width = 10\n",
    "grid_height = int(max_images / grid_width)\n",
    "# print(max_images,grid_height,grid_width)\n",
    "ni = 10\n",
    "for j in range(int(start/10),int(stop/10)):\n",
    "    jj = j*10\n",
    "    fig, axs = plt.subplots(3, ni, figsize=(20,8))\n",
    "    for i in range(ni):\n",
    "        img = db_test[jj+i][0]\n",
    "        img = img[0].data.numpy()\n",
    "        img = img[:,y_min_pad:(image_size - y_max_pad),\n",
    "                    x_min_pad:(image_size - x_max_pad)]\n",
    "        # img = cv2.resize(img,(ori_size,ori_size),interpolation=interp)\n",
    "        pred = np.nonzero((ptest[jj+i] > threshold_best).astype(int))\n",
    "        # pred_str = list(pred)\n",
    "        # pred_str = np.char.mod('%d', pred)\n",
    "        # pred_str = \" \".join(pred_str)\n",
    "        pred_str = ' '.join(map(str, pred))\n",
    "        axs[0][i].imshow(img[0], cmap=\"Reds\")\n",
    "        axs[1][i].imshow(img[1], cmap=\"Greens\")\n",
    "        axs[2][i].imshow(img[2], cmap=\"Blues\")\n",
    "#         axs[3][i].imshow(img[3], cmap=\"Oranges\")\n",
    "#         axs[0][i].set_title(pred_str)\n",
    "    # fig.suptitle(\"Top row: original, bottom row: green channel\")\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "\n",
    "#     # clean up to save on memory accumulation across folds\n",
    "#     del net\n",
    "#     del inputs, gts\n",
    "#     del image, image2\n",
    "#     del writer, scheduler, optimizer\n",
    "#     del y_pred, y_pred2\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = [test_file_list, ptest, ptesta]\n",
    "fname = 'sub/'+mname+'_'+str(fold)+'_mm.pkl'\n",
    "pickle.dump(sub,open(fname,'wb'))\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
